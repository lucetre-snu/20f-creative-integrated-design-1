{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrinkle Detection\n",
    "#### U-net w. f-1 loss\n",
    "* https://datalab.snu.ac.kr/datalab-internal/gpu-status/\n",
    "* warhol2\n",
    "  * `jupyter lab --ip=147.46.216.82 --NotebookApp.password='sha1:6d8bb616ac21:dc1b7ebffd85cb159379a282c6b49e6121e0ffb1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.cuda.device object at 0x7f8e98057940>\n",
      "4\n",
      "GeForce GTX 1080 Ti\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "# print(torch.cuda.memory_allocated())\n",
    "# print(torch.cuda.memoy_cached())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from unet.model import UNet\n",
    "from unet.dataset import *\n",
    "from unet.util import *\n",
    "from unet.train import train\n",
    "from unet.evaluate import evaluate\n",
    "from unet.loss import f1_loss, weighted_loss_and_f1_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(key, lr, batch_size, num_epoch, loss_name, data_dir, ckpt_dir, log_dir, mode, device, train_continue):\n",
    "    time = datetime.datetime.today()\n",
    "    time = time.strftime('%m-%d_%H-%M')\n",
    "    time_and_key_and_loss = time + \"_\" + key + '_'+ loss_name\n",
    "    if ckpt_dir == \"./checkpoint\":\n",
    "        ckpt_dir = os.path.join(ckpt_dir, time_and_key_and_loss)\n",
    "    log_dir = os.path.join(log_dir, time_and_key_and_loss)\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "        \n",
    "    print(f'tensorboard --logdir {log_dir} --host \"warhol1.snu.ac.kr\" --port 6006')\n",
    "    \n",
    "    # log parameters\n",
    "    print(\"learning rate: %.4e\" % lr)\n",
    "    print(\"batch size: %d\" % batch_size)\n",
    "    print(\"number of epoch: %d\" % num_epoch)\n",
    "    print(\"loss function : %s\" % loss_name)\n",
    "    print(\"data dir: %s\" % data_dir)\n",
    "    print(\"ckpt dir: %s\" % ckpt_dir)\n",
    "    print(\"log dir: %s\" % log_dir)\n",
    "    print(\"mode: %s\" % mode)\n",
    "    print(\"device: %s\" % device)\n",
    "    print(\"train_continue: %s\" % train_continue)\n",
    "    f = open(os.path.join(log_dir, 'parameter.txt'), 'w')\n",
    "    f.write(\"learning rate: %.4e\\n\" % lr)\n",
    "    f.write(\"batch size: %d\\n\" % batch_size)\n",
    "    f.write(\"number of epoch: %d\\n\" % num_epoch)\n",
    "    f.write(\"loss function : %s\\n\" % loss_name)\n",
    "    f.write(\"data dir: %s\\n\" % data_dir)\n",
    "    f.write(\"ckpt dir: %s\\n\" % ckpt_dir)\n",
    "    f.write(\"log dir: %s\\n\" % log_dir)\n",
    "    f.write(\"mode: %s\\n\" % mode)\n",
    "    f.write(\"device: %s\\n\" % device)\n",
    "    f.write(\"train_continue: %s\\n\" % train_continue)\n",
    "    f.close()\n",
    "    return ckpt_dir, log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_unet(data_dir, loss_name='weighted_BCE', lr=1e-3, batch_size=8, num_epoch=300, ckpt_dir=\"./checkpoint\", log_dir=\"./log\", mode=\"train\", train_continue=\"off\", key='eye_left'):\n",
    "    \n",
    "    train_transform = transforms.Compose([RandomResizedCrop(ratio=0.3), Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "    val_transform = transforms.Compose([Normalization(mean=0.5, std=0.5), ToTensor()])\n",
    "\n",
    "    dataset_train = Dataset(data_dir=os.path.join(data_dir, 'train'), transform=train_transform)\n",
    "    loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    dataset_val = Dataset(data_dir=os.path.join(data_dir, 'val'), transform=val_transform)\n",
    "    loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    num_data_train = len(dataset_train)\n",
    "    num_data_val = len(dataset_val)\n",
    "\n",
    "    num_batch_train = np.ceil(num_data_train / batch_size)\n",
    "    num_batch_val = np.ceil(num_data_val / batch_size)\n",
    "\n",
    "    \n",
    "    if loss_name == \"BCE\":\n",
    "        loss_function = nn.BCEWithLogitsLoss().to(device)\n",
    "    elif loss_name == \"weighted_BCE\":\n",
    "        loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5])).to(device)  # 237 - > 59 -> 15\n",
    "    elif loss_name == \"f1\":\n",
    "        loss_function = f1_loss\n",
    "    elif loss_name ==\"mix\":\n",
    "        mix_class = weighted_loss_and_f1_loss(nn.BCEWithLogitsLoss(pos_weight=torch.tensor([15])).to(device))\n",
    "        loss_function = mix_class.loss\n",
    "    else:\n",
    "        assert False, loss_name + \" is not supported\"\n",
    "        \n",
    "    ckpt_dir, log_dir = print_log(key, lr, batch_size, num_epoch, loss_name, data_dir, ckpt_dir, log_dir, mode, device, train_continue)\n",
    "        \n",
    "    net = UNet()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    \n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    writer_train = SummaryWriter(log_dir=os.path.join(log_dir, 'train'))\n",
    "    writer_val = SummaryWriter(log_dir=os.path.join(log_dir, 'val'))\n",
    "\n",
    "    train_f = open(os.path.join(log_dir, 'train.tsv'), 'w', encoding='utf-8', newline='')\n",
    "    train_wr = csv.writer(train_f, delimiter='\\t')\n",
    "    val_f = open(os.path.join(log_dir, 'val.tsv'), 'w', encoding='utf-8', newline='')\n",
    "    val_wr = csv.writer(val_f, delimiter='\\t')\n",
    "    train_wr.writerow([\"#epoch/loss/acc/f1/tp/tn/fp/fn\"])\n",
    "    val_wr.writerow([\"#epoch/loss/acc/f1/tp/tn/fp/fn\"])\n",
    "\n",
    "    ## train network\n",
    "    st_epoch = 0\n",
    "\n",
    "    if train_continue == \"on\":\n",
    "        net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "    for epoch in range(st_epoch, st_epoch + num_epoch):\n",
    "        net.train()\n",
    "        loss, acc, f1, tp, tn, fp, fn = train(net, loader_train, loss_function, num_batch_train, epoch, writer_train, device, optim)\n",
    "        train_wr.writerow((epoch, loss, acc, f1, tp, tn, fp, fn))\n",
    "\n",
    "        loss, acc, f1, tp, tn, fp, fn = evaluate(net, loader_val, loss_function, num_batch_val, epoch, writer_val, device)\n",
    "        val_wr.writerow((epoch, loss, acc, f1, tp, tn, fp, fn))\n",
    "\n",
    "        if epoch+1 == num_epoch: #((epoch+1) % (num_epoch / 10)) == 0:\n",
    "            save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch+1)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "\n",
    "    writer_train.close()\n",
    "    writer_val.close()\n",
    "    train_f.close()\n",
    "    val_f.close()\n",
    "    \n",
    "    return ckpt_dir, log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "\n",
    "def plot_f1(logs):\n",
    "    markers = (\"o\", \"x\", \"s\", \"^\")\n",
    "    colors = ('dodgerblue','mediumseagreen', 'hotpink', '#fba84a')\n",
    "    \n",
    "    def plot_train():\n",
    "        plt.rcParams[\"figure.figsize\"] = (16,4)\n",
    "        plt.rcParams['lines.linewidth'] = 2\n",
    "        plt.rcParams['lines.color'] = 'r'\n",
    "        plt.rcParams['axes.grid'] = True\n",
    "        plt.rcParams['axes.spines.right'] = False\n",
    "        plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "        plt.suptitle('F1 Score - Train', fontsize=20)\n",
    "\n",
    "        for i, k in enumerate(logs):\n",
    "            # epoch/loss/acc/f1/tp/tn/fp/fn\n",
    "            df = pd.read_csv(f\"{logs[k]}/val.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            val = df[3].to_numpy()\n",
    "            df = pd.read_csv(f\"{logs[k]}/train.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            train = df[3].to_numpy()\n",
    "            plt.plot(train, color=colors[i], marker=markers[i])\n",
    "        plt.legend(logs.keys(), fontsize=15)\n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('f1 score', fontsize=15)\n",
    "        plt.show()\n",
    "    def plot_val():\n",
    "        plt.rcParams[\"figure.figsize\"] = (16,4)\n",
    "        plt.rcParams['lines.linewidth'] = 2\n",
    "        plt.rcParams['lines.color'] = 'r'\n",
    "        plt.rcParams['axes.grid'] = True\n",
    "        plt.rcParams['axes.spines.right'] = False\n",
    "        plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "        plt.suptitle('F1 Score - Validation', fontsize=20)\n",
    "\n",
    "        for i, k in enumerate(logs):\n",
    "            # epoch/loss/acc/f1/tp/tn/fp/fn\n",
    "            df = pd.read_csv(f\"{logs[k]}/val.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            val = df[3].to_numpy()\n",
    "            df = pd.read_csv(f\"{logs[k]}/train.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            train = df[3].to_numpy()\n",
    "            plt.plot(val, color=colors[i], marker=markers[i])\n",
    "        plt.legend(logs.keys(), fontsize=15)\n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('f1 score', fontsize=15)\n",
    "        plt.show()\n",
    "    plot_train()\n",
    "    plot_val()\n",
    "    \n",
    "def plot_loss(logs):\n",
    "    markers = (\"o\", \"x\", \"s\", \"^\")\n",
    "    colors = ('dodgerblue','mediumseagreen', 'hotpink', '#fba84a')\n",
    "    \n",
    "    def plot_train():\n",
    "        plt.rcParams[\"figure.figsize\"] = (16,4)\n",
    "        plt.rcParams['lines.linewidth'] = 2\n",
    "        plt.rcParams['lines.color'] = 'r'\n",
    "        plt.rcParams['axes.grid'] = True\n",
    "        plt.rcParams['axes.spines.right'] = False\n",
    "        plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "        plt.suptitle('Loss - Train', fontsize=20)\n",
    "\n",
    "        for i, k in enumerate(logs):\n",
    "            # epoch/loss/acc/f1/tp/tn/fp/fn\n",
    "            df = pd.read_csv(f\"{logs[k]}/val.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            val = df[1].to_numpy()\n",
    "            df = pd.read_csv(f\"{logs[k]}/train.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            train = df[1].to_numpy()\n",
    "            plt.plot(train, color=colors[i], marker=markers[i])\n",
    "        plt.legend(logs.keys(), fontsize=15)\n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('loss', fontsize=15)\n",
    "        plt.show()\n",
    "    def plot_val():\n",
    "        plt.rcParams[\"figure.figsize\"] = (16,4)\n",
    "        plt.rcParams['lines.linewidth'] = 2\n",
    "        plt.rcParams['lines.color'] = 'r'\n",
    "        plt.rcParams['axes.grid'] = True\n",
    "        plt.rcParams['axes.spines.right'] = False\n",
    "        plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "        plt.suptitle('Loss - Validation', fontsize=20)\n",
    "\n",
    "        for i, k in enumerate(logs):\n",
    "            # epoch/loss/acc/f1/tp/tn/fp/fn\n",
    "            df = pd.read_csv(f\"{logs[k]}/val.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            val = df[1].to_numpy()\n",
    "            df = pd.read_csv(f\"{logs[k]}/train.tsv\", delimiter='\\t', header=None, skiprows=1)\n",
    "            train = df[1].to_numpy()\n",
    "            plt.plot(val, color=colors[i], marker=markers[i])\n",
    "        plt.legend(logs.keys(), fontsize=15)\n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('loss', fontsize=15)\n",
    "        plt.show()\n",
    "    plot_train()\n",
    "    plot_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-net baseline\n",
    "* `train_unet(data_dir, loss_name)`\n",
    "  * Loss function: `BCE`, `weight_BCE`, `f1`, `mix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = {}\n",
    "ckpts = {}\n",
    "new_dict = {\n",
    "    'eye_left': (0, 575, 220, 603),\n",
    "    'eye_right': (672, 1247, 220, 603),\n",
    "    'nose_left': (350, 573, 400, 943),\n",
    "    'nose_right': (700, 923, 400, 943),\n",
    "    'mouth': (300, 971, 940, 1195),\n",
    "    'forehead': (0, 1247, 0, 223),\n",
    "    'cheek_right': (896, 1247, 576, 1343),\n",
    "    'cheek_left': (0, 351, 576, 1343),\n",
    "    'jaw': (350, 925, 1152, 1343),\n",
    "    'center': (550, 709, 220, 955)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir ./log/12-15_21-42_eye_left_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : BCE\n",
      "data dir: ../../../split_data/eye_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-42_eye_left_BCE\n",
      "log dir: ./log/12-15_21-42_eye_left_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.4921 | ACC 0.9865 | F1 SCORE 0.0198 | TIME 12.3762\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.4644 | ACC 0.9550 | F1 SCORE 0.0176 | TIME 12.8674\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.4097 | ACC 0.9680 | F1 SCORE 0.0168 | TIME 13.3497\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.3637 | ACC 0.9863 | F1 SCORE 0.0183 | TIME 13.8421\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.3365 | ACC 0.9863 | F1 SCORE 0.0179 | TIME 14.3079\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.3216 | ACC 0.9831 | F1 SCORE 0.0241 | TIME 14.9136\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.2952 | ACC 0.9881 | F1 SCORE 0.0171 | TIME 15.3851\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.2906 | ACC 0.9813 | F1 SCORE 0.0267 | TIME 15.8644\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.2703 | ACC 0.9851 | F1 SCORE 0.0212 | TIME 16.3415\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.2683 | ACC 0.9830 | F1 SCORE 0.0239 | TIME 16.8027\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.2588 | ACC 0.9869 | F1 SCORE 0.0182 | TIME 17.2826\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.2439 | ACC 0.9840 | F1 SCORE 0.0226 | TIME 17.7977\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.2380 | ACC 0.9857 | F1 SCORE 0.0196 | TIME 18.2879\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.2296 | ACC 0.9853 | F1 SCORE 0.0209 | TIME 18.7454\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.2303 | ACC 0.9855 | F1 SCORE 0.0206 | TIME 19.2098\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.2207 | ACC 0.9814 | F1 SCORE 0.0269 | TIME 19.6960\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.2238 | ACC 0.9860 | F1 SCORE 0.0193 | TIME 20.1837\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.2103 | ACC 0.9857 | F1 SCORE 0.0204 | TIME 20.6675\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.2005 | ACC 0.9870 | F1 SCORE 0.0191 | TIME 21.1532\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.2012 | ACC 0.9822 | F1 SCORE 0.0262 | TIME 21.6138\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.1953 | ACC 0.9878 | F1 SCORE 0.0170 | TIME 22.0758\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.1964 | ACC 0.9879 | F1 SCORE 0.0170 | TIME 22.5493\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.1928 | ACC 0.9834 | F1 SCORE 0.0237 | TIME 23.0352\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.1802 | ACC 0.9867 | F1 SCORE 0.0196 | TIME 23.4999\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.1802 | ACC 0.9798 | F1 SCORE 0.0305 | TIME 23.9852\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.1777 | ACC 0.9804 | F1 SCORE 0.0281 | TIME 24.4741\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.1656 | ACC 0.9866 | F1 SCORE 0.0200 | TIME 24.9638\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.1641 | ACC 0.9893 | F1 SCORE 0.0163 | TIME 25.1391\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.2022 | ACC 0.9952 | F1 SCORE 0.0089\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.2004 | ACC 0.9963 | F1 SCORE 0.0070\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.1600 | ACC 0.9868 | F1 SCORE 0.0192 | TIME 2.2562\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.1604 | ACC 0.9844 | F1 SCORE 0.0231 | TIME 2.7450\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.1629 | ACC 0.9809 | F1 SCORE 0.0274 | TIME 3.2224\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.1560 | ACC 0.9836 | F1 SCORE 0.0239 | TIME 3.6959\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.1487 | ACC 0.9856 | F1 SCORE 0.0208 | TIME 4.1917\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.1461 | ACC 0.9844 | F1 SCORE 0.0235 | TIME 4.6754\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.1436 | ACC 0.9854 | F1 SCORE 0.0218 | TIME 5.1610\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.1423 | ACC 0.9853 | F1 SCORE 0.0229 | TIME 5.6303\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.1352 | ACC 0.9859 | F1 SCORE 0.0215 | TIME 6.1125\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.1340 | ACC 0.9856 | F1 SCORE 0.0216 | TIME 6.6070\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.1388 | ACC 0.9810 | F1 SCORE 0.0288 | TIME 7.1072\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.1371 | ACC 0.9808 | F1 SCORE 0.0303 | TIME 7.5960\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.1332 | ACC 0.9818 | F1 SCORE 0.0293 | TIME 8.0639\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.1279 | ACC 0.9822 | F1 SCORE 0.0292 | TIME 8.5382\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.1233 | ACC 0.9849 | F1 SCORE 0.0245 | TIME 9.0185\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.1208 | ACC 0.9855 | F1 SCORE 0.0230 | TIME 9.4949\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.1183 | ACC 0.9859 | F1 SCORE 0.0215 | TIME 9.9855\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.1152 | ACC 0.9872 | F1 SCORE 0.0209 | TIME 10.4493\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.1108 | ACC 0.9877 | F1 SCORE 0.0199 | TIME 10.9118\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.1102 | ACC 0.9881 | F1 SCORE 0.0183 | TIME 11.3807\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.1158 | ACC 0.9836 | F1 SCORE 0.0249 | TIME 11.8512\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.1030 | ACC 0.9893 | F1 SCORE 0.0166 | TIME 12.3296\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.1071 | ACC 0.9855 | F1 SCORE 0.0241 | TIME 12.7938\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.1022 | ACC 0.9876 | F1 SCORE 0.0193 | TIME 13.2661\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.1020 | ACC 0.9855 | F1 SCORE 0.0227 | TIME 13.7600\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.1020 | ACC 0.9850 | F1 SCORE 0.0229 | TIME 14.2608\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.1009 | ACC 0.9849 | F1 SCORE 0.0237 | TIME 14.7332\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.0914 | ACC 0.9906 | F1 SCORE 0.0141 | TIME 14.8890\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.0870 | ACC 0.9952 | F1 SCORE 0.0103\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.0843 | ACC 0.9963 | F1 SCORE 0.0079\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.0899 | ACC 0.9893 | F1 SCORE 0.0169 | TIME 2.0161\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.0927 | ACC 0.9870 | F1 SCORE 0.0211 | TIME 2.5112\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.0933 | ACC 0.9861 | F1 SCORE 0.0212 | TIME 2.9813\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.0957 | ACC 0.9840 | F1 SCORE 0.0235 | TIME 3.4488\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.0959 | ACC 0.9836 | F1 SCORE 0.0246 | TIME 3.9331\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.0908 | ACC 0.9857 | F1 SCORE 0.0220 | TIME 4.4017\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.0961 | ACC 0.9816 | F1 SCORE 0.0301 | TIME 4.8808\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.0839 | ACC 0.9883 | F1 SCORE 0.0218 | TIME 5.3684\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.0871 | ACC 0.9858 | F1 SCORE 0.0241 | TIME 5.8567\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.0912 | ACC 0.9835 | F1 SCORE 0.0258 | TIME 6.3278\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.1002 | ACC 0.9775 | F1 SCORE 0.0378 | TIME 6.8096\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.0859 | ACC 0.9861 | F1 SCORE 0.0206 | TIME 7.3031\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.0849 | ACC 0.9856 | F1 SCORE 0.0253 | TIME 7.7766\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.0830 | ACC 0.9855 | F1 SCORE 0.0280 | TIME 8.2438\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.0816 | ACC 0.9864 | F1 SCORE 0.0220 | TIME 8.7151\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.0954 | ACC 0.9782 | F1 SCORE 0.0379 | TIME 9.1855\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.0768 | ACC 0.9883 | F1 SCORE 0.0217 | TIME 9.6868\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.0841 | ACC 0.9843 | F1 SCORE 0.0275 | TIME 10.1623\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.0779 | ACC 0.9871 | F1 SCORE 0.0230 | TIME 10.6591\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.0794 | ACC 0.9850 | F1 SCORE 0.0304 | TIME 11.1588\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.0783 | ACC 0.9858 | F1 SCORE 0.0282 | TIME 11.6529\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.0754 | ACC 0.9873 | F1 SCORE 0.0236 | TIME 12.1446\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.0816 | ACC 0.9828 | F1 SCORE 0.0372 | TIME 12.6157\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.0803 | ACC 0.9841 | F1 SCORE 0.0344 | TIME 13.1066\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.0777 | ACC 0.9849 | F1 SCORE 0.0307 | TIME 13.5992\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.0771 | ACC 0.9848 | F1 SCORE 0.0326 | TIME 14.0934\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.0716 | ACC 0.9875 | F1 SCORE 0.0268 | TIME 14.5822\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.0643 | ACC 0.9914 | F1 SCORE 0.0162 | TIME 14.7388\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.0702 | ACC 0.9952 | F1 SCORE 0.0109\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.0673 | ACC 0.9963 | F1 SCORE 0.0089\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.0826 | ACC 0.9818 | F1 SCORE 0.0299 | TIME 1.9915\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.0823 | ACC 0.9813 | F1 SCORE 0.0295 | TIME 2.4864\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.0776 | ACC 0.9841 | F1 SCORE 0.0288 | TIME 2.9560\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.0719 | ACC 0.9868 | F1 SCORE 0.0278 | TIME 3.4424\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.0696 | ACC 0.9870 | F1 SCORE 0.0278 | TIME 3.9125\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.0754 | ACC 0.9840 | F1 SCORE 0.0328 | TIME 4.3891\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.0713 | ACC 0.9853 | F1 SCORE 0.0334 | TIME 4.8689\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.0663 | ACC 0.9880 | F1 SCORE 0.0258 | TIME 5.3520\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.0676 | ACC 0.9869 | F1 SCORE 0.0304 | TIME 5.8755\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.0754 | ACC 0.9834 | F1 SCORE 0.0328 | TIME 6.3628\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.0728 | ACC 0.9846 | F1 SCORE 0.0304 | TIME 6.8936\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.0697 | ACC 0.9851 | F1 SCORE 0.0352 | TIME 7.4069\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.0685 | ACC 0.9856 | F1 SCORE 0.0317 | TIME 7.8997\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.0620 | ACC 0.9887 | F1 SCORE 0.0304 | TIME 8.3835\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.0769 | ACC 0.9809 | F1 SCORE 0.0390 | TIME 8.8720\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.0639 | ACC 0.9872 | F1 SCORE 0.0311 | TIME 9.3700\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.0637 | ACC 0.9873 | F1 SCORE 0.0334 | TIME 9.8869\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.0705 | ACC 0.9840 | F1 SCORE 0.0310 | TIME 10.4585\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.0736 | ACC 0.9815 | F1 SCORE 0.0433 | TIME 10.9622\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.0687 | ACC 0.9840 | F1 SCORE 0.0343 | TIME 11.4827\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.0592 | ACC 0.9886 | F1 SCORE 0.0267 | TIME 12.0041\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.0597 | ACC 0.9880 | F1 SCORE 0.0351 | TIME 12.5628\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.0647 | ACC 0.9847 | F1 SCORE 0.0438 | TIME 13.1227\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.0701 | ACC 0.9818 | F1 SCORE 0.0536 | TIME 13.6596\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.0612 | ACC 0.9868 | F1 SCORE 0.0363 | TIME 14.1923\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.0628 | ACC 0.9854 | F1 SCORE 0.0454 | TIME 14.7209\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.0655 | ACC 0.9847 | F1 SCORE 0.0331 | TIME 15.2457\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.0772 | ACC 0.9787 | F1 SCORE 0.0480 | TIME 15.4157\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.0588 | ACC 0.9952 | F1 SCORE 0.0113\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.0557 | ACC 0.9963 | F1 SCORE 0.0097\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.0635 | ACC 0.9852 | F1 SCORE 0.0384 | TIME 2.0298\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.0703 | ACC 0.9821 | F1 SCORE 0.0442 | TIME 2.5612\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.0635 | ACC 0.9838 | F1 SCORE 0.0504 | TIME 3.0883\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.0590 | ACC 0.9860 | F1 SCORE 0.0507 | TIME 3.6145\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.0588 | ACC 0.9863 | F1 SCORE 0.0400 | TIME 4.1603\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.0618 | ACC 0.9854 | F1 SCORE 0.0349 | TIME 4.7167\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.0613 | ACC 0.9853 | F1 SCORE 0.0409 | TIME 5.2467\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.0655 | ACC 0.9825 | F1 SCORE 0.0513 | TIME 5.7753\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.0590 | ACC 0.9861 | F1 SCORE 0.0507 | TIME 6.3085\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.0545 | ACC 0.9880 | F1 SCORE 0.0409 | TIME 6.8681\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.0649 | ACC 0.9835 | F1 SCORE 0.0453 | TIME 7.3966\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.0631 | ACC 0.9838 | F1 SCORE 0.0424 | TIME 7.9257\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.0682 | ACC 0.9806 | F1 SCORE 0.0542 | TIME 8.4569\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.0619 | ACC 0.9847 | F1 SCORE 0.0520 | TIME 8.9854\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.0584 | ACC 0.9868 | F1 SCORE 0.0394 | TIME 9.5229\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.0606 | ACC 0.9850 | F1 SCORE 0.0440 | TIME 10.0510\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.0613 | ACC 0.9838 | F1 SCORE 0.0377 | TIME 10.6104\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.0532 | ACC 0.9880 | F1 SCORE 0.0340 | TIME 11.1373\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.0581 | ACC 0.9850 | F1 SCORE 0.0508 | TIME 11.6826\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.0591 | ACC 0.9851 | F1 SCORE 0.0402 | TIME 12.2222\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.0627 | ACC 0.9827 | F1 SCORE 0.0634 | TIME 12.7529\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.0572 | ACC 0.9869 | F1 SCORE 0.0398 | TIME 13.2886\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.0480 | ACC 0.9905 | F1 SCORE 0.0228 | TIME 13.8221\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.0591 | ACC 0.9857 | F1 SCORE 0.0381 | TIME 14.3644\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.0642 | ACC 0.9825 | F1 SCORE 0.0416 | TIME 14.8962\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.0569 | ACC 0.9855 | F1 SCORE 0.0390 | TIME 15.4256\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.0578 | ACC 0.9856 | F1 SCORE 0.0429 | TIME 15.9574\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.0564 | ACC 0.9855 | F1 SCORE 0.0601 | TIME 16.1388\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.0519 | ACC 0.9952 | F1 SCORE 0.0149\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.0487 | ACC 0.9963 | F1 SCORE 0.0131\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-43_eye_left_weighted_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : weighted_BCE\n",
      "data dir: ../../../split_data/eye_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-43_eye_left_weighted_BCE\n",
      "log dir: ./log/12-15_21-43_eye_left_weighted_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.7381 | ACC 0.9588 | F1 SCORE 0.0244 | TIME 2.1546\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.6886 | ACC 0.9403 | F1 SCORE 0.0254 | TIME 2.7424\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.6300 | ACC 0.9809 | F1 SCORE 0.0220 | TIME 3.2713\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.5606 | ACC 0.9814 | F1 SCORE 0.0179 | TIME 3.8058\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.5260 | ACC 0.9854 | F1 SCORE 0.0173 | TIME 4.3407\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.5040 | ACC 0.9869 | F1 SCORE 0.0191 | TIME 4.8823\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.4819 | ACC 0.9863 | F1 SCORE 0.0198 | TIME 5.4136\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.4681 | ACC 0.9841 | F1 SCORE 0.0235 | TIME 5.9483\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.4582 | ACC 0.9849 | F1 SCORE 0.0221 | TIME 6.4879\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.4314 | ACC 0.9895 | F1 SCORE 0.0155 | TIME 7.0164\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.4301 | ACC 0.9869 | F1 SCORE 0.0198 | TIME 7.5676\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.4236 | ACC 0.9859 | F1 SCORE 0.0212 | TIME 8.0970\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.4229 | ACC 0.9813 | F1 SCORE 0.0281 | TIME 8.6271\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.4213 | ACC 0.9810 | F1 SCORE 0.0279 | TIME 9.1552\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.3880 | ACC 0.9867 | F1 SCORE 0.0206 | TIME 9.6809\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.3885 | ACC 0.9857 | F1 SCORE 0.0227 | TIME 10.2207\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.3981 | ACC 0.9844 | F1 SCORE 0.0247 | TIME 10.7643\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.3743 | ACC 0.9844 | F1 SCORE 0.0256 | TIME 11.2961\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.3619 | ACC 0.9864 | F1 SCORE 0.0211 | TIME 11.8332\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.3711 | ACC 0.9822 | F1 SCORE 0.0273 | TIME 12.3700\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.3548 | ACC 0.9850 | F1 SCORE 0.0228 | TIME 12.9073\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.3640 | ACC 0.9803 | F1 SCORE 0.0311 | TIME 13.4427\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.3283 | ACC 0.9874 | F1 SCORE 0.0203 | TIME 13.9814\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.3318 | ACC 0.9844 | F1 SCORE 0.0268 | TIME 14.5134\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.3323 | ACC 0.9833 | F1 SCORE 0.0274 | TIME 15.0520\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.3012 | ACC 0.9886 | F1 SCORE 0.0191 | TIME 15.5682\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.3173 | ACC 0.9843 | F1 SCORE 0.0265 | TIME 16.0634\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.3089 | ACC 0.9862 | F1 SCORE 0.0200 | TIME 16.2295\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.3185 | ACC 0.9943 | F1 SCORE 0.0101\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.3118 | ACC 0.9954 | F1 SCORE 0.0077\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.3021 | ACC 0.9857 | F1 SCORE 0.0252 | TIME 2.2167\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.3173 | ACC 0.9826 | F1 SCORE 0.0289 | TIME 2.7247\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.2996 | ACC 0.9854 | F1 SCORE 0.0246 | TIME 3.2159\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.3051 | ACC 0.9833 | F1 SCORE 0.0278 | TIME 3.7010\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.2945 | ACC 0.9847 | F1 SCORE 0.0257 | TIME 4.1792\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.2844 | ACC 0.9857 | F1 SCORE 0.0252 | TIME 4.6546\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.2961 | ACC 0.9824 | F1 SCORE 0.0316 | TIME 5.1286\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.2962 | ACC 0.9822 | F1 SCORE 0.0314 | TIME 5.6088\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.2719 | ACC 0.9855 | F1 SCORE 0.0269 | TIME 6.0959\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.3033 | ACC 0.9789 | F1 SCORE 0.0390 | TIME 6.5672\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.2823 | ACC 0.9826 | F1 SCORE 0.0343 | TIME 7.0581\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.2701 | ACC 0.9842 | F1 SCORE 0.0335 | TIME 7.5534\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.2693 | ACC 0.9851 | F1 SCORE 0.0289 | TIME 8.0250\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.2657 | ACC 0.9839 | F1 SCORE 0.0335 | TIME 8.5189\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.2689 | ACC 0.9835 | F1 SCORE 0.0317 | TIME 9.0117\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.2542 | ACC 0.9855 | F1 SCORE 0.0295 | TIME 9.5741\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.2620 | ACC 0.9827 | F1 SCORE 0.0366 | TIME 10.0509\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.2296 | ACC 0.9896 | F1 SCORE 0.0205 | TIME 10.5274\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.2294 | ACC 0.9889 | F1 SCORE 0.0236 | TIME 10.9959\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.2387 | ACC 0.9866 | F1 SCORE 0.0262 | TIME 11.4701\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.2322 | ACC 0.9872 | F1 SCORE 0.0261 | TIME 11.9529\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.2324 | ACC 0.9876 | F1 SCORE 0.0250 | TIME 12.4332\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.2358 | ACC 0.9864 | F1 SCORE 0.0250 | TIME 12.9115\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.2334 | ACC 0.9868 | F1 SCORE 0.0237 | TIME 13.3827\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.2312 | ACC 0.9859 | F1 SCORE 0.0276 | TIME 13.8595\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.2434 | ACC 0.9839 | F1 SCORE 0.0322 | TIME 14.3355\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.2200 | ACC 0.9877 | F1 SCORE 0.0265 | TIME 14.8125\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.2565 | ACC 0.9809 | F1 SCORE 0.0397 | TIME 15.0005\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.2948 | ACC 0.9952 | F1 SCORE 0.0105\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.2904 | ACC 0.9963 | F1 SCORE 0.0084\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.2242 | ACC 0.9872 | F1 SCORE 0.0271 | TIME 2.1263\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.2258 | ACC 0.9847 | F1 SCORE 0.0369 | TIME 2.6267\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.1969 | ACC 0.9898 | F1 SCORE 0.0244 | TIME 3.1009\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.2348 | ACC 0.9831 | F1 SCORE 0.0352 | TIME 3.5851\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.2228 | ACC 0.9852 | F1 SCORE 0.0304 | TIME 4.0805\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.2443 | ACC 0.9814 | F1 SCORE 0.0430 | TIME 4.5722\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.2456 | ACC 0.9806 | F1 SCORE 0.0457 | TIME 5.0648\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.2243 | ACC 0.9857 | F1 SCORE 0.0298 | TIME 5.5493\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.1995 | ACC 0.9877 | F1 SCORE 0.0311 | TIME 6.0555\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.2380 | ACC 0.9825 | F1 SCORE 0.0371 | TIME 6.5344\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.2170 | ACC 0.9852 | F1 SCORE 0.0360 | TIME 7.0265\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.2109 | ACC 0.9857 | F1 SCORE 0.0319 | TIME 7.5163\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.2064 | ACC 0.9857 | F1 SCORE 0.0330 | TIME 8.0053\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.2172 | ACC 0.9837 | F1 SCORE 0.0434 | TIME 8.4915\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.2095 | ACC 0.9853 | F1 SCORE 0.0391 | TIME 8.9655\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.2140 | ACC 0.9848 | F1 SCORE 0.0399 | TIME 9.4551\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.2241 | ACC 0.9814 | F1 SCORE 0.0478 | TIME 9.9385\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.1979 | ACC 0.9870 | F1 SCORE 0.0354 | TIME 10.4263\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.1891 | ACC 0.9866 | F1 SCORE 0.0408 | TIME 10.9000\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.1791 | ACC 0.9886 | F1 SCORE 0.0322 | TIME 11.3751\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.1824 | ACC 0.9873 | F1 SCORE 0.0357 | TIME 11.8493\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.1948 | ACC 0.9865 | F1 SCORE 0.0321 | TIME 12.3425\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.1990 | ACC 0.9852 | F1 SCORE 0.0402 | TIME 12.8249\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.2126 | ACC 0.9817 | F1 SCORE 0.0521 | TIME 13.3194\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.2179 | ACC 0.9813 | F1 SCORE 0.0578 | TIME 13.8008\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.1984 | ACC 0.9862 | F1 SCORE 0.0435 | TIME 14.2744\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.2075 | ACC 0.9832 | F1 SCORE 0.0537 | TIME 14.7498\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.1749 | ACC 0.9903 | F1 SCORE 0.0221 | TIME 14.9334\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.1700 | ACC 0.9952 | F1 SCORE 0.0124\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.1598 | ACC 0.9963 | F1 SCORE 0.0099\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.2057 | ACC 0.9828 | F1 SCORE 0.0467 | TIME 2.1293\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.2045 | ACC 0.9840 | F1 SCORE 0.0381 | TIME 2.6332\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.1874 | ACC 0.9861 | F1 SCORE 0.0353 | TIME 3.1097\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.1680 | ACC 0.9887 | F1 SCORE 0.0290 | TIME 3.5806\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.1668 | ACC 0.9887 | F1 SCORE 0.0288 | TIME 4.0515\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.1982 | ACC 0.9833 | F1 SCORE 0.0446 | TIME 4.5294\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.1760 | ACC 0.9869 | F1 SCORE 0.0393 | TIME 5.0385\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.2172 | ACC 0.9810 | F1 SCORE 0.0540 | TIME 5.5227\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.1996 | ACC 0.9822 | F1 SCORE 0.0594 | TIME 6.0318\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.1822 | ACC 0.9850 | F1 SCORE 0.0529 | TIME 6.5488\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.2145 | ACC 0.9804 | F1 SCORE 0.0630 | TIME 7.0478\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.1719 | ACC 0.9880 | F1 SCORE 0.0382 | TIME 7.5410\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.1981 | ACC 0.9825 | F1 SCORE 0.0560 | TIME 8.0478\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.1799 | ACC 0.9855 | F1 SCORE 0.0455 | TIME 8.5732\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.1903 | ACC 0.9836 | F1 SCORE 0.0560 | TIME 9.0694\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.1877 | ACC 0.9849 | F1 SCORE 0.0446 | TIME 9.5571\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.1610 | ACC 0.9892 | F1 SCORE 0.0313 | TIME 10.0571\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.1675 | ACC 0.9871 | F1 SCORE 0.0431 | TIME 10.5559\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.1675 | ACC 0.9869 | F1 SCORE 0.0417 | TIME 11.0806\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.1534 | ACC 0.9895 | F1 SCORE 0.0322 | TIME 11.6208\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.1541 | ACC 0.9885 | F1 SCORE 0.0403 | TIME 12.1495\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.1900 | ACC 0.9830 | F1 SCORE 0.0536 | TIME 12.6953\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.1820 | ACC 0.9833 | F1 SCORE 0.0592 | TIME 13.2282\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.1909 | ACC 0.9838 | F1 SCORE 0.0541 | TIME 13.7696\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.1835 | ACC 0.9851 | F1 SCORE 0.0564 | TIME 14.2980\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.1635 | ACC 0.9862 | F1 SCORE 0.0555 | TIME 14.8375\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.2019 | ACC 0.9815 | F1 SCORE 0.0616 | TIME 15.3763\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.1537 | ACC 0.9869 | F1 SCORE 0.0571 | TIME 15.5538\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.1691 | ACC 0.9952 | F1 SCORE 0.0125\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.1598 | ACC 0.9963 | F1 SCORE 0.0102\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.1767 | ACC 0.9840 | F1 SCORE 0.0593 | TIME 2.1519\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.1663 | ACC 0.9850 | F1 SCORE 0.0621 | TIME 2.7400\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.1624 | ACC 0.9882 | F1 SCORE 0.0391 | TIME 3.2810\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.1653 | ACC 0.9864 | F1 SCORE 0.0493 | TIME 3.8531\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.1860 | ACC 0.9817 | F1 SCORE 0.0703 | TIME 4.3929\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.1837 | ACC 0.9827 | F1 SCORE 0.0632 | TIME 4.9259\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.1782 | ACC 0.9829 | F1 SCORE 0.0727 | TIME 5.4600\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.1735 | ACC 0.9848 | F1 SCORE 0.0600 | TIME 5.9878\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.1558 | ACC 0.9871 | F1 SCORE 0.0585 | TIME 6.5238\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.1532 | ACC 0.9870 | F1 SCORE 0.0620 | TIME 7.0621\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.1407 | ACC 0.9891 | F1 SCORE 0.0455 | TIME 7.6289\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.1536 | ACC 0.9875 | F1 SCORE 0.0443 | TIME 8.1678\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.2059 | ACC 0.9816 | F1 SCORE 0.0515 | TIME 8.7325\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.1935 | ACC 0.9813 | F1 SCORE 0.0682 | TIME 9.2708\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.1697 | ACC 0.9849 | F1 SCORE 0.0584 | TIME 9.8110\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.1774 | ACC 0.9833 | F1 SCORE 0.0687 | TIME 10.3485\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.1794 | ACC 0.9836 | F1 SCORE 0.0729 | TIME 10.8859\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.1730 | ACC 0.9843 | F1 SCORE 0.0677 | TIME 11.4212\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.1603 | ACC 0.9858 | F1 SCORE 0.0674 | TIME 11.9633\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.1530 | ACC 0.9864 | F1 SCORE 0.0655 | TIME 12.5927\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.1451 | ACC 0.9886 | F1 SCORE 0.0433 | TIME 13.1318\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.1493 | ACC 0.9871 | F1 SCORE 0.0520 | TIME 13.6686\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.1710 | ACC 0.9839 | F1 SCORE 0.0612 | TIME 14.2040\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.1416 | ACC 0.9887 | F1 SCORE 0.0417 | TIME 14.7435\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.1563 | ACC 0.9866 | F1 SCORE 0.0515 | TIME 15.2857\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.1751 | ACC 0.9833 | F1 SCORE 0.0665 | TIME 15.8252\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.2100 | ACC 0.9778 | F1 SCORE 0.0789 | TIME 16.3671\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.1824 | ACC 0.9834 | F1 SCORE 0.0604 | TIME 16.5451\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.2934 | ACC 0.9952 | F1 SCORE 0.0128\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.2944 | ACC 0.9963 | F1 SCORE 0.0097\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-45_eye_left_f1 --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : f1\n",
      "data dir: ../../../split_data/eye_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-45_eye_left_f1\n",
      "log dir: ./log/12-15_21-45_eye_left_f1\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.9787 | ACC 0.9662 | F1 SCORE 0.0213 | TIME 2.1618\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.9681 | ACC 0.7816 | F1 SCORE 0.0319 | TIME 2.7220\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.9626 | ACC 0.7431 | F1 SCORE 0.0374 | TIME 3.2613\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.9525 | ACC 0.7557 | F1 SCORE 0.0475 | TIME 3.7961\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.9592 | ACC 0.7853 | F1 SCORE 0.0408 | TIME 4.3315\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.9464 | ACC 0.8126 | F1 SCORE 0.0536 | TIME 4.8746\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.9610 | ACC 0.7988 | F1 SCORE 0.0390 | TIME 5.4098\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.9558 | ACC 0.7969 | F1 SCORE 0.0442 | TIME 5.9510\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.9696 | ACC 0.8012 | F1 SCORE 0.0304 | TIME 6.4997\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.9487 | ACC 0.7852 | F1 SCORE 0.0513 | TIME 7.0375\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.9694 | ACC 0.8042 | F1 SCORE 0.0306 | TIME 7.5753\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.9575 | ACC 0.8370 | F1 SCORE 0.0425 | TIME 8.1223\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.9579 | ACC 0.8365 | F1 SCORE 0.0421 | TIME 8.6659\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.9541 | ACC 0.8654 | F1 SCORE 0.0459 | TIME 9.2047\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.9483 | ACC 0.8463 | F1 SCORE 0.0517 | TIME 9.7526\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.9565 | ACC 0.8487 | F1 SCORE 0.0435 | TIME 10.3220\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.9509 | ACC 0.8405 | F1 SCORE 0.0491 | TIME 10.8614\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.9605 | ACC 0.8589 | F1 SCORE 0.0395 | TIME 11.4033\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.9475 | ACC 0.8736 | F1 SCORE 0.0525 | TIME 11.9443\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.9518 | ACC 0.8596 | F1 SCORE 0.0482 | TIME 12.4921\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.9649 | ACC 0.8747 | F1 SCORE 0.0351 | TIME 13.0424\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.9532 | ACC 0.8567 | F1 SCORE 0.0468 | TIME 13.5834\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.9553 | ACC 0.8374 | F1 SCORE 0.0447 | TIME 14.1252\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.9468 | ACC 0.8564 | F1 SCORE 0.0532 | TIME 14.6366\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.9443 | ACC 0.8662 | F1 SCORE 0.0557 | TIME 15.1247\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.9170 | ACC 0.8876 | F1 SCORE 0.0830 | TIME 15.6356\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.9384 | ACC 0.8921 | F1 SCORE 0.0616 | TIME 16.1154\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.9539 | ACC 0.8776 | F1 SCORE 0.0461 | TIME 16.2749\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.9872 | ACC 0.4242 | F1 SCORE 0.0128\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.9905 | ACC 0.4101 | F1 SCORE 0.0095\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.9437 | ACC 0.8543 | F1 SCORE 0.0563 | TIME 2.3034\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.9337 | ACC 0.8591 | F1 SCORE 0.0663 | TIME 2.8458\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.9387 | ACC 0.8704 | F1 SCORE 0.0613 | TIME 3.3187\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.9387 | ACC 0.8857 | F1 SCORE 0.0613 | TIME 3.8037\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.9330 | ACC 0.8867 | F1 SCORE 0.0670 | TIME 4.2788\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.9339 | ACC 0.8867 | F1 SCORE 0.0661 | TIME 4.7561\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.9328 | ACC 0.9188 | F1 SCORE 0.0672 | TIME 5.2317\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.9425 | ACC 0.9197 | F1 SCORE 0.0575 | TIME 5.7108\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.9158 | ACC 0.9106 | F1 SCORE 0.0842 | TIME 6.2150\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.9349 | ACC 0.8924 | F1 SCORE 0.0651 | TIME 6.6893\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.9325 | ACC 0.9014 | F1 SCORE 0.0675 | TIME 7.1643\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.9236 | ACC 0.9020 | F1 SCORE 0.0764 | TIME 7.6414\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.9284 | ACC 0.9067 | F1 SCORE 0.0716 | TIME 8.1466\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.9077 | ACC 0.9100 | F1 SCORE 0.0923 | TIME 8.6235\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.9276 | ACC 0.9064 | F1 SCORE 0.0724 | TIME 9.1256\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.9256 | ACC 0.9219 | F1 SCORE 0.0744 | TIME 9.6107\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.9488 | ACC 0.9339 | F1 SCORE 0.0512 | TIME 10.1099\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.9276 | ACC 0.9250 | F1 SCORE 0.0724 | TIME 10.5871\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.9078 | ACC 0.9266 | F1 SCORE 0.0922 | TIME 11.0717\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.8915 | ACC 0.9241 | F1 SCORE 0.1085 | TIME 11.5715\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.9139 | ACC 0.9189 | F1 SCORE 0.0861 | TIME 12.0532\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.9475 | ACC 0.9142 | F1 SCORE 0.0525 | TIME 12.5542\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.9377 | ACC 0.9071 | F1 SCORE 0.0623 | TIME 13.0624\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.9076 | ACC 0.9162 | F1 SCORE 0.0924 | TIME 13.5483\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.9136 | ACC 0.9207 | F1 SCORE 0.0864 | TIME 14.0346\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.9010 | ACC 0.9323 | F1 SCORE 0.0990 | TIME 14.5119\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.9076 | ACC 0.9324 | F1 SCORE 0.0924 | TIME 14.9874\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.8882 | ACC 0.9270 | F1 SCORE 0.1118 | TIME 15.1511\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.9787 | ACC 0.9517 | F1 SCORE 0.0213\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.9826 | ACC 0.9470 | F1 SCORE 0.0174\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.9047 | ACC 0.9283 | F1 SCORE 0.0953 | TIME 2.1182\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.9144 | ACC 0.9356 | F1 SCORE 0.0856 | TIME 2.6635\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.9036 | ACC 0.9403 | F1 SCORE 0.0964 | TIME 3.1641\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.8983 | ACC 0.9395 | F1 SCORE 0.1017 | TIME 3.6753\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.9276 | ACC 0.9219 | F1 SCORE 0.0724 | TIME 4.2302\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.8926 | ACC 0.9232 | F1 SCORE 0.1074 | TIME 4.7827\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.8862 | ACC 0.9246 | F1 SCORE 0.1138 | TIME 5.3180\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.8833 | ACC 0.9238 | F1 SCORE 0.1167 | TIME 5.8653\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.9072 | ACC 0.9358 | F1 SCORE 0.0928 | TIME 6.4429\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.8991 | ACC 0.9343 | F1 SCORE 0.1009 | TIME 6.9799\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.8793 | ACC 0.9360 | F1 SCORE 0.1207 | TIME 7.5202\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.9322 | ACC 0.9375 | F1 SCORE 0.0678 | TIME 8.0573\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.9105 | ACC 0.9437 | F1 SCORE 0.0895 | TIME 8.5907\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.8565 | ACC 0.9431 | F1 SCORE 0.1435 | TIME 9.1197\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.8868 | ACC 0.9430 | F1 SCORE 0.1132 | TIME 9.6524\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.8938 | ACC 0.9455 | F1 SCORE 0.1062 | TIME 10.1883\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.8912 | ACC 0.9454 | F1 SCORE 0.1088 | TIME 10.7499\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.9053 | ACC 0.9440 | F1 SCORE 0.0947 | TIME 11.2903\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.8779 | ACC 0.9493 | F1 SCORE 0.1221 | TIME 11.8271\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.8876 | ACC 0.9504 | F1 SCORE 0.1124 | TIME 12.3671\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.9008 | ACC 0.9545 | F1 SCORE 0.0992 | TIME 12.9057\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.8833 | ACC 0.9531 | F1 SCORE 0.1167 | TIME 13.4732\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.8892 | ACC 0.9582 | F1 SCORE 0.1108 | TIME 14.0073\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.8845 | ACC 0.9645 | F1 SCORE 0.1155 | TIME 14.5501\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.8848 | ACC 0.9647 | F1 SCORE 0.1152 | TIME 15.1105\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.8865 | ACC 0.9676 | F1 SCORE 0.1135 | TIME 15.6618\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.8649 | ACC 0.9633 | F1 SCORE 0.1351 | TIME 16.2875\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.7882 | ACC 0.9460 | F1 SCORE 0.2118 | TIME 16.4662\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.9750 | ACC 0.9600 | F1 SCORE 0.0250\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.9784 | ACC 0.9571 | F1 SCORE 0.0216\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.8364 | ACC 0.9412 | F1 SCORE 0.1636 | TIME 2.1644\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.8702 | ACC 0.9449 | F1 SCORE 0.1298 | TIME 2.7177\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.8864 | ACC 0.9517 | F1 SCORE 0.1136 | TIME 3.2571\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.8519 | ACC 0.9549 | F1 SCORE 0.1481 | TIME 3.8054\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.8599 | ACC 0.9667 | F1 SCORE 0.1401 | TIME 4.3357\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.8822 | ACC 0.9683 | F1 SCORE 0.1178 | TIME 4.8754\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.8391 | ACC 0.9673 | F1 SCORE 0.1609 | TIME 5.4074\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.8456 | ACC 0.9684 | F1 SCORE 0.1544 | TIME 5.9470\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.8185 | ACC 0.9623 | F1 SCORE 0.1815 | TIME 6.4877\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.8406 | ACC 0.9673 | F1 SCORE 0.1594 | TIME 7.0242\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.8352 | ACC 0.9641 | F1 SCORE 0.1648 | TIME 7.5608\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.8237 | ACC 0.9629 | F1 SCORE 0.1763 | TIME 8.0859\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.8075 | ACC 0.9636 | F1 SCORE 0.1925 | TIME 8.6216\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.8237 | ACC 0.9659 | F1 SCORE 0.1763 | TIME 9.1559\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.8671 | ACC 0.9714 | F1 SCORE 0.1329 | TIME 9.7160\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.8271 | ACC 0.9748 | F1 SCORE 0.1729 | TIME 10.2579\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.8137 | ACC 0.9679 | F1 SCORE 0.1863 | TIME 10.7981\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.8391 | ACC 0.9643 | F1 SCORE 0.1609 | TIME 11.3343\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.8006 | ACC 0.9640 | F1 SCORE 0.1994 | TIME 11.8738\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.8614 | ACC 0.9674 | F1 SCORE 0.1386 | TIME 12.4042\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.8405 | ACC 0.9673 | F1 SCORE 0.1595 | TIME 12.9434\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.8073 | ACC 0.9712 | F1 SCORE 0.1927 | TIME 13.4804\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.8110 | ACC 0.9687 | F1 SCORE 0.1890 | TIME 14.0196\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.8465 | ACC 0.9723 | F1 SCORE 0.1535 | TIME 14.5641\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.8386 | ACC 0.9750 | F1 SCORE 0.1614 | TIME 15.1117\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.8347 | ACC 0.9789 | F1 SCORE 0.1653 | TIME 15.6504\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.7791 | ACC 0.9725 | F1 SCORE 0.2209 | TIME 16.1804\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.7661 | ACC 0.9711 | F1 SCORE 0.2339 | TIME 16.3743\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.9743 | ACC 0.9590 | F1 SCORE 0.0257\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.9735 | ACC 0.9573 | F1 SCORE 0.0265\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.7966 | ACC 0.9668 | F1 SCORE 0.2034 | TIME 2.0900\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.8081 | ACC 0.9697 | F1 SCORE 0.1919 | TIME 2.6437\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.8011 | ACC 0.9677 | F1 SCORE 0.1989 | TIME 3.1856\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.7813 | ACC 0.9690 | F1 SCORE 0.2187 | TIME 3.7218\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.7984 | ACC 0.9715 | F1 SCORE 0.2016 | TIME 4.2582\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.7691 | ACC 0.9716 | F1 SCORE 0.2309 | TIME 4.8027\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.7551 | ACC 0.9717 | F1 SCORE 0.2449 | TIME 5.3448\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.8015 | ACC 0.9759 | F1 SCORE 0.1985 | TIME 5.8826\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.7857 | ACC 0.9727 | F1 SCORE 0.2143 | TIME 6.4240\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.7603 | ACC 0.9744 | F1 SCORE 0.2397 | TIME 6.9662\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.7750 | ACC 0.9791 | F1 SCORE 0.2250 | TIME 7.4981\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.7411 | ACC 0.9807 | F1 SCORE 0.2589 | TIME 8.0317\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.7288 | ACC 0.9762 | F1 SCORE 0.2712 | TIME 8.5717\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.7686 | ACC 0.9801 | F1 SCORE 0.2314 | TIME 9.0736\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.8148 | ACC 0.9728 | F1 SCORE 0.1852 | TIME 9.5603\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.7626 | ACC 0.9774 | F1 SCORE 0.2374 | TIME 10.0776\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.7867 | ACC 0.9774 | F1 SCORE 0.2133 | TIME 10.5598\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.7709 | ACC 0.9799 | F1 SCORE 0.2291 | TIME 11.0447\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.7667 | ACC 0.9781 | F1 SCORE 0.2333 | TIME 11.5227\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.8329 | ACC 0.9835 | F1 SCORE 0.1671 | TIME 11.9978\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.7985 | ACC 0.9782 | F1 SCORE 0.2015 | TIME 12.4909\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.7450 | ACC 0.9759 | F1 SCORE 0.2550 | TIME 12.9757\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.7360 | ACC 0.9762 | F1 SCORE 0.2640 | TIME 13.4552\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.7721 | ACC 0.9762 | F1 SCORE 0.2279 | TIME 13.9385\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.7824 | ACC 0.9772 | F1 SCORE 0.2176 | TIME 14.4179\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.7689 | ACC 0.9757 | F1 SCORE 0.2311 | TIME 14.9021\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.7044 | ACC 0.9737 | F1 SCORE 0.2956 | TIME 15.3854\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.7935 | ACC 0.9775 | F1 SCORE 0.2065 | TIME 15.5591\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.9598 | ACC 0.9821 | F1 SCORE 0.0402\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.9525 | ACC 0.9819 | F1 SCORE 0.0475\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-46_eye_left_mix --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : mix\n",
      "data dir: ../../../split_data/eye_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-46_eye_left_mix\n",
      "log dir: ./log/12-15_21-46_eye_left_mix\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.9366 | ACC 0.8889 | F1 SCORE 0.0213 | TIME 2.0664\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.9044 | ACC 0.7874 | F1 SCORE 0.0205 | TIME 2.6060\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.8864 | ACC 0.9364 | F1 SCORE 0.0218 | TIME 3.0997\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.8604 | ACC 0.9330 | F1 SCORE 0.0262 | TIME 3.5960\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.8418 | ACC 0.9206 | F1 SCORE 0.0324 | TIME 4.1136\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.8254 | ACC 0.9281 | F1 SCORE 0.0295 | TIME 4.5969\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.8084 | ACC 0.9540 | F1 SCORE 0.0286 | TIME 5.0874\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.8097 | ACC 0.9597 | F1 SCORE 0.0320 | TIME 5.5787\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.7996 | ACC 0.9659 | F1 SCORE 0.0274 | TIME 6.0760\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.7768 | ACC 0.9686 | F1 SCORE 0.0279 | TIME 6.5912\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.7870 | ACC 0.9727 | F1 SCORE 0.0284 | TIME 7.0742\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.7753 | ACC 0.9741 | F1 SCORE 0.0301 | TIME 7.5854\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.7646 | ACC 0.9756 | F1 SCORE 0.0266 | TIME 8.0861\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.7667 | ACC 0.9693 | F1 SCORE 0.0345 | TIME 8.5634\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.7469 | ACC 0.9691 | F1 SCORE 0.0265 | TIME 9.0426\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.7534 | ACC 0.9678 | F1 SCORE 0.0323 | TIME 9.5221\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.7523 | ACC 0.9711 | F1 SCORE 0.0364 | TIME 10.0290\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.7425 | ACC 0.9706 | F1 SCORE 0.0302 | TIME 10.5338\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.7415 | ACC 0.9786 | F1 SCORE 0.0258 | TIME 11.0188\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.7349 | ACC 0.9773 | F1 SCORE 0.0318 | TIME 11.5004\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.7366 | ACC 0.9672 | F1 SCORE 0.0307 | TIME 11.9825\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.7249 | ACC 0.9698 | F1 SCORE 0.0366 | TIME 12.4692\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.7200 | ACC 0.9625 | F1 SCORE 0.0397 | TIME 12.9538\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.7040 | ACC 0.9646 | F1 SCORE 0.0251 | TIME 13.4609\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.7219 | ACC 0.9694 | F1 SCORE 0.0266 | TIME 13.9781\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.7083 | ACC 0.9807 | F1 SCORE 0.0254 | TIME 14.4622\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.7141 | ACC 0.9826 | F1 SCORE 0.0302 | TIME 14.9524\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.7123 | ACC 0.9810 | F1 SCORE 0.0286 | TIME 15.1129\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.7201 | ACC 0.9939 | F1 SCORE 0.0094\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.7115 | ACC 0.9953 | F1 SCORE 0.0072\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.7141 | ACC 0.9732 | F1 SCORE 0.0401 | TIME 2.3728\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.7029 | ACC 0.9690 | F1 SCORE 0.0371 | TIME 2.9919\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.7327 | ACC 0.9592 | F1 SCORE 0.0458 | TIME 3.5251\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.7080 | ACC 0.9579 | F1 SCORE 0.0383 | TIME 4.0776\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.6977 | ACC 0.9538 | F1 SCORE 0.0410 | TIME 4.6171\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.6941 | ACC 0.9638 | F1 SCORE 0.0437 | TIME 5.1609\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.6997 | ACC 0.9677 | F1 SCORE 0.0422 | TIME 5.7278\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.6791 | ACC 0.9688 | F1 SCORE 0.0381 | TIME 6.2908\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.6883 | ACC 0.9726 | F1 SCORE 0.0416 | TIME 6.8374\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.6986 | ACC 0.9594 | F1 SCORE 0.0517 | TIME 7.3945\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.6796 | ACC 0.9597 | F1 SCORE 0.0276 | TIME 7.9520\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.6849 | ACC 0.9675 | F1 SCORE 0.0399 | TIME 8.5029\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.6805 | ACC 0.9681 | F1 SCORE 0.0489 | TIME 9.0550\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.6784 | ACC 0.9705 | F1 SCORE 0.0417 | TIME 9.5827\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.6690 | ACC 0.9731 | F1 SCORE 0.0378 | TIME 10.1692\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.6671 | ACC 0.9736 | F1 SCORE 0.0486 | TIME 10.7160\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.6708 | ACC 0.9702 | F1 SCORE 0.0425 | TIME 11.2820\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.6613 | ACC 0.9746 | F1 SCORE 0.0317 | TIME 11.9376\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.6819 | ACC 0.9723 | F1 SCORE 0.0572 | TIME 12.4893\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.6601 | ACC 0.9679 | F1 SCORE 0.0395 | TIME 13.0442\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.6645 | ACC 0.9605 | F1 SCORE 0.0564 | TIME 13.5819\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.6589 | ACC 0.9600 | F1 SCORE 0.0549 | TIME 14.1221\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.6548 | ACC 0.9596 | F1 SCORE 0.0386 | TIME 14.6752\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.6553 | ACC 0.9620 | F1 SCORE 0.0417 | TIME 15.2228\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.6628 | ACC 0.9610 | F1 SCORE 0.0596 | TIME 15.7630\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.6439 | ACC 0.9722 | F1 SCORE 0.0407 | TIME 16.2948\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.6505 | ACC 0.9762 | F1 SCORE 0.0486 | TIME 16.8274\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.6681 | ACC 0.9715 | F1 SCORE 0.0646 | TIME 17.0041\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.6640 | ACC 0.9652 | F1 SCORE 0.0139\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.6528 | ACC 0.9640 | F1 SCORE 0.0115\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.6603 | ACC 0.9602 | F1 SCORE 0.0580 | TIME 2.2179\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.6484 | ACC 0.9532 | F1 SCORE 0.0500 | TIME 2.7784\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.6823 | ACC 0.9466 | F1 SCORE 0.0633 | TIME 3.3265\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.6567 | ACC 0.9591 | F1 SCORE 0.0713 | TIME 3.8956\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.6621 | ACC 0.9662 | F1 SCORE 0.0518 | TIME 4.4801\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.6711 | ACC 0.9647 | F1 SCORE 0.0604 | TIME 5.0305\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.6468 | ACC 0.9684 | F1 SCORE 0.0543 | TIME 5.5804\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.6580 | ACC 0.9666 | F1 SCORE 0.0692 | TIME 6.1393\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.6509 | ACC 0.9681 | F1 SCORE 0.0399 | TIME 6.6952\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.6587 | ACC 0.9671 | F1 SCORE 0.0581 | TIME 7.2640\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.6460 | ACC 0.9652 | F1 SCORE 0.0611 | TIME 7.8199\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.6519 | ACC 0.9638 | F1 SCORE 0.0514 | TIME 8.3878\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.6416 | ACC 0.9683 | F1 SCORE 0.0558 | TIME 8.9514\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.6374 | ACC 0.9668 | F1 SCORE 0.0414 | TIME 9.5155\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.6524 | ACC 0.9641 | F1 SCORE 0.0681 | TIME 10.0871\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.6333 | ACC 0.9689 | F1 SCORE 0.0561 | TIME 10.6473\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.6259 | ACC 0.9719 | F1 SCORE 0.0430 | TIME 11.1884\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.6311 | ACC 0.9679 | F1 SCORE 0.0531 | TIME 11.7296\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.6436 | ACC 0.9658 | F1 SCORE 0.0724 | TIME 12.2942\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.6167 | ACC 0.9633 | F1 SCORE 0.0710 | TIME 12.8547\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.6247 | ACC 0.9627 | F1 SCORE 0.0659 | TIME 13.3932\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.6225 | ACC 0.9557 | F1 SCORE 0.0635 | TIME 13.9375\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.6196 | ACC 0.9659 | F1 SCORE 0.0502 | TIME 14.5039\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.6272 | ACC 0.9715 | F1 SCORE 0.0500 | TIME 15.0716\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.6095 | ACC 0.9678 | F1 SCORE 0.0665 | TIME 15.6156\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.6242 | ACC 0.9702 | F1 SCORE 0.0586 | TIME 16.1845\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.6164 | ACC 0.9669 | F1 SCORE 0.0703 | TIME 16.7522\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.6564 | ACC 0.9559 | F1 SCORE 0.1116 | TIME 16.9527\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.6328 | ACC 0.9723 | F1 SCORE 0.0177\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.6198 | ACC 0.9694 | F1 SCORE 0.0158\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.6242 | ACC 0.9567 | F1 SCORE 0.0449 | TIME 2.1660\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.6332 | ACC 0.9555 | F1 SCORE 0.0765 | TIME 2.7539\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.6287 | ACC 0.9539 | F1 SCORE 0.0695 | TIME 3.3017\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.6361 | ACC 0.9585 | F1 SCORE 0.0636 | TIME 3.8657\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.6384 | ACC 0.9633 | F1 SCORE 0.0644 | TIME 4.4213\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.6159 | ACC 0.9671 | F1 SCORE 0.0677 | TIME 4.9395\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.6385 | ACC 0.9712 | F1 SCORE 0.0580 | TIME 5.4387\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.6300 | ACC 0.9667 | F1 SCORE 0.0773 | TIME 5.9492\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.6283 | ACC 0.9662 | F1 SCORE 0.0763 | TIME 6.4524\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.6211 | ACC 0.9690 | F1 SCORE 0.0765 | TIME 6.9501\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.6257 | ACC 0.9646 | F1 SCORE 0.0954 | TIME 7.4276\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.6192 | ACC 0.9643 | F1 SCORE 0.0763 | TIME 7.9353\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.6136 | ACC 0.9585 | F1 SCORE 0.0740 | TIME 8.4338\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.6080 | ACC 0.9528 | F1 SCORE 0.1017 | TIME 8.9426\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.6004 | ACC 0.9553 | F1 SCORE 0.0736 | TIME 9.4446\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.6084 | ACC 0.9538 | F1 SCORE 0.0741 | TIME 9.9549\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.6038 | ACC 0.9570 | F1 SCORE 0.0744 | TIME 10.4605\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.5885 | ACC 0.9626 | F1 SCORE 0.0849 | TIME 10.9748\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.6092 | ACC 0.9631 | F1 SCORE 0.0854 | TIME 11.4775\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.5891 | ACC 0.9706 | F1 SCORE 0.0564 | TIME 11.9926\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.6225 | ACC 0.9669 | F1 SCORE 0.0919 | TIME 12.5049\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.5971 | ACC 0.9615 | F1 SCORE 0.0856 | TIME 13.0017\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.5958 | ACC 0.9607 | F1 SCORE 0.0872 | TIME 13.4912\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.5961 | ACC 0.9594 | F1 SCORE 0.0623 | TIME 13.9676\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.6219 | ACC 0.9555 | F1 SCORE 0.0947 | TIME 14.4503\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.5956 | ACC 0.9646 | F1 SCORE 0.0871 | TIME 14.9257\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.6010 | ACC 0.9680 | F1 SCORE 0.0534 | TIME 15.3996\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.6160 | ACC 0.9675 | F1 SCORE 0.0918 | TIME 15.5653\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.6502 | ACC 0.9789 | F1 SCORE 0.0159\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.6424 | ACC 0.9769 | F1 SCORE 0.0127\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.6099 | ACC 0.9690 | F1 SCORE 0.0913 | TIME 2.2432\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.6074 | ACC 0.9680 | F1 SCORE 0.0933 | TIME 2.7579\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.6008 | ACC 0.9673 | F1 SCORE 0.0733 | TIME 3.2352\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.6122 | ACC 0.9633 | F1 SCORE 0.1156 | TIME 3.7224\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.5937 | ACC 0.9608 | F1 SCORE 0.0883 | TIME 4.2224\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.6191 | ACC 0.9580 | F1 SCORE 0.0861 | TIME 4.7320\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.5960 | ACC 0.9631 | F1 SCORE 0.0730 | TIME 5.2134\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.5933 | ACC 0.9615 | F1 SCORE 0.0816 | TIME 5.6896\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.6136 | ACC 0.9652 | F1 SCORE 0.0778 | TIME 6.1754\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.6029 | ACC 0.9623 | F1 SCORE 0.1066 | TIME 6.6556\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.5843 | ACC 0.9662 | F1 SCORE 0.0973 | TIME 7.1287\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.5816 | ACC 0.9672 | F1 SCORE 0.0932 | TIME 7.6209\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.5759 | ACC 0.9695 | F1 SCORE 0.0911 | TIME 8.1179\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.5925 | ACC 0.9683 | F1 SCORE 0.1051 | TIME 8.6001\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.5759 | ACC 0.9668 | F1 SCORE 0.0931 | TIME 9.0747\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.6008 | ACC 0.9637 | F1 SCORE 0.0909 | TIME 9.5475\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.5799 | ACC 0.9580 | F1 SCORE 0.1048 | TIME 10.0302\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.5998 | ACC 0.9576 | F1 SCORE 0.0824 | TIME 10.5113\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.5910 | ACC 0.9623 | F1 SCORE 0.0814 | TIME 11.0120\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.5763 | ACC 0.9644 | F1 SCORE 0.0861 | TIME 11.5075\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.5913 | ACC 0.9668 | F1 SCORE 0.1086 | TIME 11.9943\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.5777 | ACC 0.9699 | F1 SCORE 0.0918 | TIME 12.4839\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.5753 | ACC 0.9688 | F1 SCORE 0.0867 | TIME 13.0445\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.5790 | ACC 0.9659 | F1 SCORE 0.1016 | TIME 13.5271\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.5915 | ACC 0.9640 | F1 SCORE 0.1046 | TIME 14.0039\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.5971 | ACC 0.9605 | F1 SCORE 0.1165 | TIME 14.4810\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.5781 | ACC 0.9617 | F1 SCORE 0.1076 | TIME 14.9694\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.5703 | ACC 0.9650 | F1 SCORE 0.0676 | TIME 15.1441\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.6265 | ACC 0.9689 | F1 SCORE 0.0212\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.6129 | ACC 0.9665 | F1 SCORE 0.0181\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-48_eye_right_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : BCE\n",
      "data dir: ../../../split_data/eye_right/\n",
      "ckpt dir: ./checkpoint/12-15_21-48_eye_right_BCE\n",
      "log dir: ./log/12-15_21-48_eye_right_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.7169 | ACC 0.9660 | F1 SCORE 0.0166 | TIME 2.1649\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.6685 | ACC 0.9470 | F1 SCORE 0.0208 | TIME 2.6848\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.5990 | ACC 0.9813 | F1 SCORE 0.0246 | TIME 3.1772\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.5443 | ACC 0.9851 | F1 SCORE 0.0209 | TIME 3.6691\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.5067 | ACC 0.9873 | F1 SCORE 0.0173 | TIME 4.1672\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.4921 | ACC 0.9805 | F1 SCORE 0.0244 | TIME 4.6607\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.4733 | ACC 0.9814 | F1 SCORE 0.0246 | TIME 5.1728\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.4367 | ACC 0.9851 | F1 SCORE 0.0204 | TIME 5.6722\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.4226 | ACC 0.9798 | F1 SCORE 0.0281 | TIME 6.1719\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.4113 | ACC 0.9873 | F1 SCORE 0.0177 | TIME 6.6487\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.4013 | ACC 0.9841 | F1 SCORE 0.0224 | TIME 7.1604\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.3885 | ACC 0.9818 | F1 SCORE 0.0256 | TIME 7.6897\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.3863 | ACC 0.9795 | F1 SCORE 0.0282 | TIME 8.1939\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.3728 | ACC 0.9809 | F1 SCORE 0.0271 | TIME 8.6855\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.3555 | ACC 0.9853 | F1 SCORE 0.0203 | TIME 9.1808\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.3495 | ACC 0.9816 | F1 SCORE 0.0256 | TIME 9.6671\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.3382 | ACC 0.9854 | F1 SCORE 0.0197 | TIME 10.1819\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.3270 | ACC 0.9841 | F1 SCORE 0.0226 | TIME 10.6792\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.3169 | ACC 0.9879 | F1 SCORE 0.0171 | TIME 11.1824\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.3091 | ACC 0.9839 | F1 SCORE 0.0229 | TIME 11.6749\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.2985 | ACC 0.9833 | F1 SCORE 0.0238 | TIME 12.1574\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.2915 | ACC 0.9860 | F1 SCORE 0.0201 | TIME 12.6479\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.2894 | ACC 0.9835 | F1 SCORE 0.0236 | TIME 13.1455\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.2786 | ACC 0.9838 | F1 SCORE 0.0224 | TIME 13.6470\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.2773 | ACC 0.9825 | F1 SCORE 0.0252 | TIME 14.1199\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.2868 | ACC 0.9838 | F1 SCORE 0.0228 | TIME 14.5937\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.2769 | ACC 0.9843 | F1 SCORE 0.0218 | TIME 15.1029\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.2725 | ACC 0.9848 | F1 SCORE 0.0213 | TIME 15.2641\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.3664 | ACC 0.9957 | F1 SCORE 0.0085\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.3637 | ACC 0.9947 | F1 SCORE 0.0106\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.2580 | ACC 0.9814 | F1 SCORE 0.0268 | TIME 2.4929\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.2528 | ACC 0.9846 | F1 SCORE 0.0230 | TIME 2.9990\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.2503 | ACC 0.9834 | F1 SCORE 0.0237 | TIME 3.4830\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.2429 | ACC 0.9835 | F1 SCORE 0.0232 | TIME 3.9549\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.2404 | ACC 0.9799 | F1 SCORE 0.0266 | TIME 4.4306\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.2331 | ACC 0.9847 | F1 SCORE 0.0203 | TIME 4.9244\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.2324 | ACC 0.9804 | F1 SCORE 0.0276 | TIME 5.4073\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.2242 | ACC 0.9814 | F1 SCORE 0.0254 | TIME 5.9095\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.2186 | ACC 0.9827 | F1 SCORE 0.0242 | TIME 6.4200\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.2098 | ACC 0.9834 | F1 SCORE 0.0245 | TIME 6.8935\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.2059 | ACC 0.9836 | F1 SCORE 0.0234 | TIME 7.3892\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.2032 | ACC 0.9852 | F1 SCORE 0.0211 | TIME 7.8630\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.1998 | ACC 0.9833 | F1 SCORE 0.0227 | TIME 8.3586\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.2002 | ACC 0.9793 | F1 SCORE 0.0274 | TIME 8.8379\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.1880 | ACC 0.9862 | F1 SCORE 0.0192 | TIME 9.3071\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.1864 | ACC 0.9871 | F1 SCORE 0.0181 | TIME 9.7787\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.1882 | ACC 0.9820 | F1 SCORE 0.0257 | TIME 10.2669\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.1872 | ACC 0.9812 | F1 SCORE 0.0257 | TIME 10.7579\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.1782 | ACC 0.9858 | F1 SCORE 0.0201 | TIME 11.2641\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.1782 | ACC 0.9837 | F1 SCORE 0.0229 | TIME 11.7474\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.1702 | ACC 0.9878 | F1 SCORE 0.0173 | TIME 12.2452\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.1709 | ACC 0.9843 | F1 SCORE 0.0231 | TIME 12.7646\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.1697 | ACC 0.9857 | F1 SCORE 0.0202 | TIME 13.2645\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.1654 | ACC 0.9858 | F1 SCORE 0.0193 | TIME 13.7669\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.1660 | ACC 0.9832 | F1 SCORE 0.0234 | TIME 14.2447\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.1578 | ACC 0.9871 | F1 SCORE 0.0184 | TIME 14.7467\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.1566 | ACC 0.9851 | F1 SCORE 0.0209 | TIME 15.2334\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.1582 | ACC 0.9864 | F1 SCORE 0.0184 | TIME 15.4147\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.1711 | ACC 0.9957 | F1 SCORE 0.0089\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.1738 | ACC 0.9947 | F1 SCORE 0.0112\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.1523 | ACC 0.9869 | F1 SCORE 0.0177 | TIME 2.2686\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.1517 | ACC 0.9839 | F1 SCORE 0.0234 | TIME 2.7649\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.1501 | ACC 0.9849 | F1 SCORE 0.0218 | TIME 3.2480\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.1481 | ACC 0.9840 | F1 SCORE 0.0235 | TIME 3.7448\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.1532 | ACC 0.9789 | F1 SCORE 0.0298 | TIME 4.2232\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.1522 | ACC 0.9775 | F1 SCORE 0.0326 | TIME 4.6958\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.1400 | ACC 0.9866 | F1 SCORE 0.0194 | TIME 5.1765\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.1406 | ACC 0.9838 | F1 SCORE 0.0225 | TIME 5.6506\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.1342 | ACC 0.9881 | F1 SCORE 0.0172 | TIME 6.1482\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.1350 | ACC 0.9859 | F1 SCORE 0.0203 | TIME 6.6344\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.1359 | ACC 0.9833 | F1 SCORE 0.0226 | TIME 7.1328\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.1320 | ACC 0.9850 | F1 SCORE 0.0209 | TIME 7.6353\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.1360 | ACC 0.9828 | F1 SCORE 0.0231 | TIME 8.1049\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.1307 | ACC 0.9836 | F1 SCORE 0.0233 | TIME 8.5868\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.1386 | ACC 0.9781 | F1 SCORE 0.0305 | TIME 9.0923\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.1311 | ACC 0.9817 | F1 SCORE 0.0257 | TIME 9.5738\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.1201 | ACC 0.9877 | F1 SCORE 0.0173 | TIME 10.0518\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.1254 | ACC 0.9837 | F1 SCORE 0.0234 | TIME 10.5194\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.1273 | ACC 0.9808 | F1 SCORE 0.0287 | TIME 10.9918\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.1164 | ACC 0.9876 | F1 SCORE 0.0183 | TIME 11.4771\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.1192 | ACC 0.9853 | F1 SCORE 0.0215 | TIME 12.1209\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.1177 | ACC 0.9847 | F1 SCORE 0.0217 | TIME 12.6001\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.1214 | ACC 0.9826 | F1 SCORE 0.0251 | TIME 13.0843\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.1137 | ACC 0.9856 | F1 SCORE 0.0211 | TIME 13.5635\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.1156 | ACC 0.9841 | F1 SCORE 0.0226 | TIME 14.0606\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.1166 | ACC 0.9826 | F1 SCORE 0.0252 | TIME 14.5520\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.1105 | ACC 0.9854 | F1 SCORE 0.0209 | TIME 15.0423\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.1160 | ACC 0.9831 | F1 SCORE 0.0244 | TIME 15.2092\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.1023 | ACC 0.9957 | F1 SCORE 0.0093\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.1041 | ACC 0.9947 | F1 SCORE 0.0120\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.1097 | ACC 0.9847 | F1 SCORE 0.0215 | TIME 2.1145\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.1079 | ACC 0.9854 | F1 SCORE 0.0217 | TIME 2.6705\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.1051 | ACC 0.9864 | F1 SCORE 0.0208 | TIME 3.2378\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.1049 | ACC 0.9856 | F1 SCORE 0.0228 | TIME 3.7745\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.1047 | ACC 0.9849 | F1 SCORE 0.0214 | TIME 4.3053\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.1031 | ACC 0.9854 | F1 SCORE 0.0215 | TIME 4.8412\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.0994 | ACC 0.9870 | F1 SCORE 0.0204 | TIME 5.3747\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.1038 | ACC 0.9837 | F1 SCORE 0.0246 | TIME 5.9127\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.1098 | ACC 0.9801 | F1 SCORE 0.0289 | TIME 6.4462\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.1051 | ACC 0.9819 | F1 SCORE 0.0270 | TIME 6.9854\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.0990 | ACC 0.9851 | F1 SCORE 0.0231 | TIME 7.5223\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.1025 | ACC 0.9820 | F1 SCORE 0.0282 | TIME 8.0715\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.1055 | ACC 0.9800 | F1 SCORE 0.0308 | TIME 8.6083\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.0992 | ACC 0.9838 | F1 SCORE 0.0252 | TIME 9.1504\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.1021 | ACC 0.9810 | F1 SCORE 0.0291 | TIME 9.6878\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.1010 | ACC 0.9810 | F1 SCORE 0.0302 | TIME 10.2225\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.0949 | ACC 0.9849 | F1 SCORE 0.0230 | TIME 10.7593\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.0998 | ACC 0.9811 | F1 SCORE 0.0336 | TIME 11.2961\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.0942 | ACC 0.9841 | F1 SCORE 0.0256 | TIME 11.8378\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.0922 | ACC 0.9851 | F1 SCORE 0.0235 | TIME 12.3746\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.0920 | ACC 0.9842 | F1 SCORE 0.0257 | TIME 12.9212\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.0896 | ACC 0.9854 | F1 SCORE 0.0237 | TIME 13.4868\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.0865 | ACC 0.9871 | F1 SCORE 0.0197 | TIME 14.0280\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.0882 | ACC 0.9855 | F1 SCORE 0.0245 | TIME 14.5832\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.0976 | ACC 0.9793 | F1 SCORE 0.0334 | TIME 15.1195\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.0863 | ACC 0.9852 | F1 SCORE 0.0269 | TIME 15.6599\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.0862 | ACC 0.9854 | F1 SCORE 0.0238 | TIME 16.1981\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.0893 | ACC 0.9839 | F1 SCORE 0.0306 | TIME 16.3750\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.0760 | ACC 0.9957 | F1 SCORE 0.0104\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.0780 | ACC 0.9947 | F1 SCORE 0.0145\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.0906 | ACC 0.9823 | F1 SCORE 0.0317 | TIME 2.2120\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.0876 | ACC 0.9842 | F1 SCORE 0.0248 | TIME 2.7989\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.0859 | ACC 0.9844 | F1 SCORE 0.0266 | TIME 3.3662\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.0923 | ACC 0.9807 | F1 SCORE 0.0341 | TIME 3.9061\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.0859 | ACC 0.9845 | F1 SCORE 0.0220 | TIME 4.4603\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.0858 | ACC 0.9830 | F1 SCORE 0.0287 | TIME 5.0140\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.0839 | ACC 0.9844 | F1 SCORE 0.0256 | TIME 5.5471\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.0849 | ACC 0.9827 | F1 SCORE 0.0324 | TIME 6.0954\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.0836 | ACC 0.9835 | F1 SCORE 0.0296 | TIME 6.6580\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.0903 | ACC 0.9797 | F1 SCORE 0.0348 | TIME 7.2187\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.0825 | ACC 0.9837 | F1 SCORE 0.0284 | TIME 7.7679\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.0765 | ACC 0.9875 | F1 SCORE 0.0216 | TIME 8.3011\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.0862 | ACC 0.9812 | F1 SCORE 0.0336 | TIME 8.8389\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.0803 | ACC 0.9842 | F1 SCORE 0.0288 | TIME 9.3831\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.0786 | ACC 0.9838 | F1 SCORE 0.0323 | TIME 9.9233\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.0841 | ACC 0.9818 | F1 SCORE 0.0328 | TIME 10.4591\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.0760 | ACC 0.9859 | F1 SCORE 0.0275 | TIME 10.9941\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.0792 | ACC 0.9838 | F1 SCORE 0.0308 | TIME 11.5306\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.0816 | ACC 0.9823 | F1 SCORE 0.0342 | TIME 12.0742\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.0749 | ACC 0.9861 | F1 SCORE 0.0283 | TIME 12.6149\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.0748 | ACC 0.9857 | F1 SCORE 0.0274 | TIME 13.1526\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.0733 | ACC 0.9857 | F1 SCORE 0.0299 | TIME 13.6926\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.0740 | ACC 0.9855 | F1 SCORE 0.0292 | TIME 14.2403\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.0772 | ACC 0.9840 | F1 SCORE 0.0293 | TIME 14.7817\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.0709 | ACC 0.9866 | F1 SCORE 0.0268 | TIME 15.3224\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.0826 | ACC 0.9802 | F1 SCORE 0.0369 | TIME 15.8628\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.0708 | ACC 0.9865 | F1 SCORE 0.0250 | TIME 16.4016\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.0647 | ACC 0.9885 | F1 SCORE 0.0271 | TIME 16.5771\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.0602 | ACC 0.9957 | F1 SCORE 0.0118\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.0626 | ACC 0.9947 | F1 SCORE 0.0165\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-49_eye_right_weighted_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : weighted_BCE\n",
      "data dir: ../../../split_data/eye_right/\n",
      "ckpt dir: ./checkpoint/12-15_21-49_eye_right_weighted_BCE\n",
      "log dir: ./log/12-15_21-49_eye_right_weighted_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.8342 | ACC 0.8393 | F1 SCORE 0.0227 | TIME 2.2012\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.7851 | ACC 0.7976 | F1 SCORE 0.0271 | TIME 2.7210\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.7039 | ACC 0.9622 | F1 SCORE 0.0264 | TIME 3.2164\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.6445 | ACC 0.9712 | F1 SCORE 0.0218 | TIME 3.7100\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.6100 | ACC 0.9785 | F1 SCORE 0.0287 | TIME 4.2209\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.5609 | ACC 0.9828 | F1 SCORE 0.0236 | TIME 4.7514\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.5424 | ACC 0.9825 | F1 SCORE 0.0202 | TIME 5.2594\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.5317 | ACC 0.9853 | F1 SCORE 0.0209 | TIME 5.7598\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.5064 | ACC 0.9854 | F1 SCORE 0.0206 | TIME 6.2864\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.5002 | ACC 0.9842 | F1 SCORE 0.0223 | TIME 6.7887\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.4921 | ACC 0.9824 | F1 SCORE 0.0232 | TIME 7.3201\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.4756 | ACC 0.9815 | F1 SCORE 0.0254 | TIME 7.8543\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.4429 | ACC 0.9867 | F1 SCORE 0.0177 | TIME 8.3842\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.4406 | ACC 0.9851 | F1 SCORE 0.0212 | TIME 8.9116\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.4488 | ACC 0.9829 | F1 SCORE 0.0247 | TIME 9.4354\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.4479 | ACC 0.9783 | F1 SCORE 0.0329 | TIME 9.9775\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.4160 | ACC 0.9854 | F1 SCORE 0.0221 | TIME 10.5317\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.4073 | ACC 0.9847 | F1 SCORE 0.0237 | TIME 11.0872\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.4055 | ACC 0.9812 | F1 SCORE 0.0276 | TIME 11.6293\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.4076 | ACC 0.9816 | F1 SCORE 0.0296 | TIME 12.2450\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.3837 | ACC 0.9835 | F1 SCORE 0.0247 | TIME 12.7920\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.3614 | ACC 0.9873 | F1 SCORE 0.0207 | TIME 13.3283\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.3625 | ACC 0.9859 | F1 SCORE 0.0225 | TIME 13.8686\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.3651 | ACC 0.9836 | F1 SCORE 0.0254 | TIME 14.4041\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.3601 | ACC 0.9839 | F1 SCORE 0.0233 | TIME 14.9452\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.3558 | ACC 0.9836 | F1 SCORE 0.0249 | TIME 15.4852\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.3494 | ACC 0.9838 | F1 SCORE 0.0259 | TIME 16.0242\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.3384 | ACC 0.9860 | F1 SCORE 0.0206 | TIME 16.2198\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.3338 | ACC 0.9956 | F1 SCORE 0.0084\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.3400 | ACC 0.9946 | F1 SCORE 0.0107\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.3376 | ACC 0.9846 | F1 SCORE 0.0234 | TIME 2.5630\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.3412 | ACC 0.9823 | F1 SCORE 0.0282 | TIME 3.1446\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.3253 | ACC 0.9851 | F1 SCORE 0.0237 | TIME 3.6787\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.3504 | ACC 0.9780 | F1 SCORE 0.0359 | TIME 4.2167\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.3209 | ACC 0.9835 | F1 SCORE 0.0272 | TIME 4.7557\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.3259 | ACC 0.9818 | F1 SCORE 0.0316 | TIME 5.2950\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.3261 | ACC 0.9803 | F1 SCORE 0.0327 | TIME 5.8453\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.2939 | ACC 0.9874 | F1 SCORE 0.0210 | TIME 6.3969\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.3019 | ACC 0.9843 | F1 SCORE 0.0256 | TIME 6.9254\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.2993 | ACC 0.9851 | F1 SCORE 0.0252 | TIME 7.4802\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.2843 | ACC 0.9875 | F1 SCORE 0.0220 | TIME 8.0227\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.3038 | ACC 0.9826 | F1 SCORE 0.0311 | TIME 8.5837\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.3017 | ACC 0.9829 | F1 SCORE 0.0275 | TIME 9.1383\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.3140 | ACC 0.9788 | F1 SCORE 0.0376 | TIME 9.6947\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.2796 | ACC 0.9861 | F1 SCORE 0.0227 | TIME 10.2468\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.2703 | ACC 0.9860 | F1 SCORE 0.0249 | TIME 10.7697\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.2752 | ACC 0.9849 | F1 SCORE 0.0253 | TIME 11.3248\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.2760 | ACC 0.9840 | F1 SCORE 0.0267 | TIME 11.8881\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.2674 | ACC 0.9859 | F1 SCORE 0.0251 | TIME 12.4370\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.2738 | ACC 0.9840 | F1 SCORE 0.0282 | TIME 12.9989\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.2466 | ACC 0.9883 | F1 SCORE 0.0219 | TIME 13.5652\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.2759 | ACC 0.9820 | F1 SCORE 0.0332 | TIME 14.1359\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.2643 | ACC 0.9834 | F1 SCORE 0.0341 | TIME 14.7010\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.2560 | ACC 0.9851 | F1 SCORE 0.0293 | TIME 15.2617\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.2916 | ACC 0.9784 | F1 SCORE 0.0410 | TIME 15.8100\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.2621 | ACC 0.9837 | F1 SCORE 0.0337 | TIME 16.3639\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.2546 | ACC 0.9870 | F1 SCORE 0.0223 | TIME 16.9288\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.2286 | ACC 0.9911 | F1 SCORE 0.0165 | TIME 17.1053\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.2255 | ACC 0.9957 | F1 SCORE 0.0099\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.2300 | ACC 0.9947 | F1 SCORE 0.0140\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.2746 | ACC 0.9802 | F1 SCORE 0.0378 | TIME 2.2732\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.2602 | ACC 0.9828 | F1 SCORE 0.0311 | TIME 2.8377\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.2537 | ACC 0.9830 | F1 SCORE 0.0304 | TIME 3.3744\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.2478 | ACC 0.9852 | F1 SCORE 0.0257 | TIME 3.9130\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.2327 | ACC 0.9859 | F1 SCORE 0.0298 | TIME 4.4841\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.2389 | ACC 0.9850 | F1 SCORE 0.0294 | TIME 5.0432\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.2329 | ACC 0.9858 | F1 SCORE 0.0288 | TIME 5.6313\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.2290 | ACC 0.9868 | F1 SCORE 0.0249 | TIME 6.1532\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.2425 | ACC 0.9841 | F1 SCORE 0.0306 | TIME 6.6776\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.2532 | ACC 0.9809 | F1 SCORE 0.0389 | TIME 7.1975\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.2302 | ACC 0.9853 | F1 SCORE 0.0276 | TIME 7.6959\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.2627 | ACC 0.9807 | F1 SCORE 0.0368 | TIME 8.1721\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.2490 | ACC 0.9803 | F1 SCORE 0.0463 | TIME 8.6566\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.2230 | ACC 0.9857 | F1 SCORE 0.0296 | TIME 9.1626\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.2315 | ACC 0.9837 | F1 SCORE 0.0365 | TIME 9.6735\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.2334 | ACC 0.9829 | F1 SCORE 0.0407 | TIME 10.1748\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.2033 | ACC 0.9877 | F1 SCORE 0.0323 | TIME 10.6788\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.2291 | ACC 0.9840 | F1 SCORE 0.0363 | TIME 11.1780\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.2229 | ACC 0.9853 | F1 SCORE 0.0349 | TIME 11.6779\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.2213 | ACC 0.9843 | F1 SCORE 0.0351 | TIME 12.2058\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.2299 | ACC 0.9816 | F1 SCORE 0.0485 | TIME 12.7174\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.2247 | ACC 0.9829 | F1 SCORE 0.0392 | TIME 13.2191\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.2004 | ACC 0.9864 | F1 SCORE 0.0390 | TIME 13.7241\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.2224 | ACC 0.9828 | F1 SCORE 0.0455 | TIME 14.2643\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.2085 | ACC 0.9854 | F1 SCORE 0.0415 | TIME 14.7637\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.2040 | ACC 0.9861 | F1 SCORE 0.0375 | TIME 15.2753\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.2353 | ACC 0.9801 | F1 SCORE 0.0523 | TIME 15.7901\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.2028 | ACC 0.9861 | F1 SCORE 0.0360 | TIME 15.9936\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.1834 | ACC 0.9957 | F1 SCORE 0.0115\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.1875 | ACC 0.9947 | F1 SCORE 0.0181\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.2344 | ACC 0.9806 | F1 SCORE 0.0434 | TIME 2.1968\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.2150 | ACC 0.9839 | F1 SCORE 0.0371 | TIME 2.7501\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.2129 | ACC 0.9840 | F1 SCORE 0.0373 | TIME 3.2908\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.2277 | ACC 0.9801 | F1 SCORE 0.0534 | TIME 3.8273\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.1981 | ACC 0.9857 | F1 SCORE 0.0398 | TIME 4.3907\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.2001 | ACC 0.9860 | F1 SCORE 0.0358 | TIME 4.9303\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.2240 | ACC 0.9813 | F1 SCORE 0.0485 | TIME 5.4712\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.1988 | ACC 0.9859 | F1 SCORE 0.0325 | TIME 6.0150\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.2409 | ACC 0.9776 | F1 SCORE 0.0590 | TIME 6.5721\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.1957 | ACC 0.9846 | F1 SCORE 0.0464 | TIME 7.1063\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.2118 | ACC 0.9830 | F1 SCORE 0.0479 | TIME 7.6438\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.1910 | ACC 0.9854 | F1 SCORE 0.0442 | TIME 8.1834\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.2053 | ACC 0.9813 | F1 SCORE 0.0656 | TIME 8.7219\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.2092 | ACC 0.9824 | F1 SCORE 0.0492 | TIME 9.2625\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.1965 | ACC 0.9839 | F1 SCORE 0.0500 | TIME 9.8055\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.1881 | ACC 0.9854 | F1 SCORE 0.0432 | TIME 10.3421\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.1696 | ACC 0.9875 | F1 SCORE 0.0432 | TIME 10.8805\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.1976 | ACC 0.9816 | F1 SCORE 0.0631 | TIME 11.4202\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.1786 | ACC 0.9853 | F1 SCORE 0.0547 | TIME 11.9570\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.1932 | ACC 0.9838 | F1 SCORE 0.0537 | TIME 12.4998\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.1828 | ACC 0.9856 | F1 SCORE 0.0485 | TIME 13.0468\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.1870 | ACC 0.9853 | F1 SCORE 0.0452 | TIME 13.5864\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.1776 | ACC 0.9857 | F1 SCORE 0.0436 | TIME 14.1260\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.1873 | ACC 0.9843 | F1 SCORE 0.0481 | TIME 14.6756\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.2041 | ACC 0.9818 | F1 SCORE 0.0542 | TIME 15.2143\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.1865 | ACC 0.9854 | F1 SCORE 0.0496 | TIME 15.7544\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.1685 | ACC 0.9860 | F1 SCORE 0.0546 | TIME 16.2969\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.2257 | ACC 0.9803 | F1 SCORE 0.0560 | TIME 16.4812\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.1980 | ACC 0.9957 | F1 SCORE 0.0139\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.2048 | ACC 0.9947 | F1 SCORE 0.0202\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.1935 | ACC 0.9836 | F1 SCORE 0.0549 | TIME 2.3110\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.1834 | ACC 0.9829 | F1 SCORE 0.0674 | TIME 2.8573\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.1624 | ACC 0.9865 | F1 SCORE 0.0563 | TIME 3.3912\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.1827 | ACC 0.9829 | F1 SCORE 0.0624 | TIME 3.9371\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.1565 | ACC 0.9873 | F1 SCORE 0.0492 | TIME 4.4814\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.1754 | ACC 0.9845 | F1 SCORE 0.0561 | TIME 5.0228\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.2141 | ACC 0.9787 | F1 SCORE 0.0784 | TIME 5.5634\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.2011 | ACC 0.9810 | F1 SCORE 0.0732 | TIME 6.1139\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.1850 | ACC 0.9833 | F1 SCORE 0.0635 | TIME 6.6609\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.1781 | ACC 0.9842 | F1 SCORE 0.0633 | TIME 7.2046\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.1910 | ACC 0.9814 | F1 SCORE 0.0675 | TIME 7.7468\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.2011 | ACC 0.9797 | F1 SCORE 0.0736 | TIME 8.2926\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.1970 | ACC 0.9803 | F1 SCORE 0.0780 | TIME 8.8366\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.1760 | ACC 0.9841 | F1 SCORE 0.0668 | TIME 9.3765\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.1812 | ACC 0.9811 | F1 SCORE 0.0902 | TIME 9.9163\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.1663 | ACC 0.9847 | F1 SCORE 0.0679 | TIME 10.4596\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.1573 | ACC 0.9866 | F1 SCORE 0.0579 | TIME 11.0027\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.1577 | ACC 0.9867 | F1 SCORE 0.0559 | TIME 11.5440\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.1689 | ACC 0.9849 | F1 SCORE 0.0561 | TIME 12.0870\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.1444 | ACC 0.9877 | F1 SCORE 0.0539 | TIME 12.6336\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.1793 | ACC 0.9830 | F1 SCORE 0.0735 | TIME 13.1780\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.1671 | ACC 0.9838 | F1 SCORE 0.0750 | TIME 13.7181\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.1618 | ACC 0.9849 | F1 SCORE 0.0670 | TIME 14.2625\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.1493 | ACC 0.9861 | F1 SCORE 0.0736 | TIME 14.8055\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.1705 | ACC 0.9852 | F1 SCORE 0.0645 | TIME 15.3039\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.1558 | ACC 0.9849 | F1 SCORE 0.0775 | TIME 15.7956\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.1567 | ACC 0.9854 | F1 SCORE 0.0733 | TIME 16.3031\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.1668 | ACC 0.9839 | F1 SCORE 0.0686 | TIME 16.4671\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.1573 | ACC 0.9957 | F1 SCORE 0.0183\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.1627 | ACC 0.9947 | F1 SCORE 0.0266\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-51_eye_right_f1 --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : f1\n",
      "data dir: ../../../split_data/eye_right/\n",
      "ckpt dir: ./checkpoint/12-15_21-51_eye_right_f1\n",
      "log dir: ./log/12-15_21-51_eye_right_f1\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.9784 | ACC 0.9434 | F1 SCORE 0.0216 | TIME 2.2647\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.9763 | ACC 0.6737 | F1 SCORE 0.0237 | TIME 2.8024\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.9585 | ACC 0.6195 | F1 SCORE 0.0415 | TIME 3.3184\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.9615 | ACC 0.7309 | F1 SCORE 0.0385 | TIME 3.8576\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.9603 | ACC 0.7721 | F1 SCORE 0.0397 | TIME 4.3976\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.9603 | ACC 0.7227 | F1 SCORE 0.0397 | TIME 4.9476\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.9527 | ACC 0.7591 | F1 SCORE 0.0473 | TIME 5.4832\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.9523 | ACC 0.7751 | F1 SCORE 0.0477 | TIME 6.0263\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.9545 | ACC 0.7575 | F1 SCORE 0.0455 | TIME 6.5723\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.9619 | ACC 0.7897 | F1 SCORE 0.0381 | TIME 7.1178\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.9603 | ACC 0.8046 | F1 SCORE 0.0397 | TIME 7.6409\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.9623 | ACC 0.8359 | F1 SCORE 0.0377 | TIME 8.1747\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.9236 | ACC 0.8118 | F1 SCORE 0.0764 | TIME 8.7123\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.9481 | ACC 0.8076 | F1 SCORE 0.0519 | TIME 9.2476\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.9417 | ACC 0.8344 | F1 SCORE 0.0583 | TIME 9.7764\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.9540 | ACC 0.8570 | F1 SCORE 0.0460 | TIME 10.3118\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.9514 | ACC 0.8446 | F1 SCORE 0.0486 | TIME 10.8462\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.9531 | ACC 0.7986 | F1 SCORE 0.0469 | TIME 11.3788\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.9480 | ACC 0.8277 | F1 SCORE 0.0520 | TIME 11.9131\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.9467 | ACC 0.8474 | F1 SCORE 0.0533 | TIME 12.4424\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.9333 | ACC 0.8556 | F1 SCORE 0.0667 | TIME 12.9763\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.9611 | ACC 0.8413 | F1 SCORE 0.0389 | TIME 13.5047\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.9365 | ACC 0.8450 | F1 SCORE 0.0635 | TIME 14.0378\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.9435 | ACC 0.8659 | F1 SCORE 0.0565 | TIME 14.5772\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.9440 | ACC 0.8524 | F1 SCORE 0.0560 | TIME 15.1127\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.9355 | ACC 0.8635 | F1 SCORE 0.0645 | TIME 15.6464\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.9400 | ACC 0.8886 | F1 SCORE 0.0600 | TIME 16.1809\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.9408 | ACC 0.8757 | F1 SCORE 0.0592 | TIME 16.3474\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.9863 | ACC 0.6888 | F1 SCORE 0.0137\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.9825 | ACC 0.6766 | F1 SCORE 0.0175\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.9165 | ACC 0.8942 | F1 SCORE 0.0835 | TIME 2.2717\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.9417 | ACC 0.8918 | F1 SCORE 0.0583 | TIME 2.8236\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.9211 | ACC 0.8938 | F1 SCORE 0.0789 | TIME 3.3474\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.9366 | ACC 0.9066 | F1 SCORE 0.0634 | TIME 3.8777\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.9182 | ACC 0.8853 | F1 SCORE 0.0818 | TIME 4.4090\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.9299 | ACC 0.8987 | F1 SCORE 0.0701 | TIME 4.9508\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.9360 | ACC 0.9146 | F1 SCORE 0.0640 | TIME 5.4882\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.9313 | ACC 0.9008 | F1 SCORE 0.0687 | TIME 6.0486\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.9157 | ACC 0.8844 | F1 SCORE 0.0843 | TIME 6.5962\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.9308 | ACC 0.8856 | F1 SCORE 0.0692 | TIME 7.1321\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.9369 | ACC 0.8984 | F1 SCORE 0.0631 | TIME 7.6680\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.9385 | ACC 0.8878 | F1 SCORE 0.0615 | TIME 8.2010\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.9243 | ACC 0.8825 | F1 SCORE 0.0757 | TIME 8.7373\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.9167 | ACC 0.8817 | F1 SCORE 0.0833 | TIME 9.2641\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.9156 | ACC 0.8851 | F1 SCORE 0.0844 | TIME 9.8908\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.9287 | ACC 0.8916 | F1 SCORE 0.0713 | TIME 10.4215\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.8995 | ACC 0.9209 | F1 SCORE 0.1005 | TIME 10.9596\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.9322 | ACC 0.9190 | F1 SCORE 0.0678 | TIME 11.4968\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.9175 | ACC 0.9091 | F1 SCORE 0.0825 | TIME 12.0399\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.9205 | ACC 0.9016 | F1 SCORE 0.0795 | TIME 12.5874\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.9051 | ACC 0.9143 | F1 SCORE 0.0949 | TIME 13.1267\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.9156 | ACC 0.9207 | F1 SCORE 0.0844 | TIME 13.6711\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.9125 | ACC 0.9226 | F1 SCORE 0.0875 | TIME 14.2135\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.9129 | ACC 0.9198 | F1 SCORE 0.0871 | TIME 14.7645\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.8982 | ACC 0.9185 | F1 SCORE 0.1018 | TIME 15.3079\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.9093 | ACC 0.9118 | F1 SCORE 0.0907 | TIME 15.8457\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.9099 | ACC 0.9152 | F1 SCORE 0.0901 | TIME 16.3854\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.9301 | ACC 0.9205 | F1 SCORE 0.0699 | TIME 16.5617\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.9770 | ACC 0.9155 | F1 SCORE 0.0230\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.9689 | ACC 0.9126 | F1 SCORE 0.0311\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.9150 | ACC 0.9147 | F1 SCORE 0.0850 | TIME 2.3700\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.9136 | ACC 0.9269 | F1 SCORE 0.0864 | TIME 2.9239\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.9069 | ACC 0.9310 | F1 SCORE 0.0931 | TIME 3.4569\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.9012 | ACC 0.9375 | F1 SCORE 0.0988 | TIME 4.0055\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.8700 | ACC 0.9331 | F1 SCORE 0.1300 | TIME 4.5116\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.9121 | ACC 0.9356 | F1 SCORE 0.0879 | TIME 5.0308\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.8816 | ACC 0.9327 | F1 SCORE 0.1184 | TIME 5.5562\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.8873 | ACC 0.9349 | F1 SCORE 0.1127 | TIME 6.0415\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.8853 | ACC 0.9365 | F1 SCORE 0.1147 | TIME 6.5267\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.8936 | ACC 0.9335 | F1 SCORE 0.1064 | TIME 7.0141\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.8942 | ACC 0.9421 | F1 SCORE 0.1058 | TIME 7.5084\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.8779 | ACC 0.9499 | F1 SCORE 0.1221 | TIME 8.0197\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.8699 | ACC 0.9524 | F1 SCORE 0.1301 | TIME 8.5391\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.8846 | ACC 0.9448 | F1 SCORE 0.1154 | TIME 9.0496\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.8935 | ACC 0.9462 | F1 SCORE 0.1065 | TIME 9.5562\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.8780 | ACC 0.9458 | F1 SCORE 0.1220 | TIME 10.0662\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.8774 | ACC 0.9502 | F1 SCORE 0.1226 | TIME 10.5835\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.8578 | ACC 0.9548 | F1 SCORE 0.1422 | TIME 11.0973\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.8799 | ACC 0.9551 | F1 SCORE 0.1201 | TIME 11.6052\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.8551 | ACC 0.9529 | F1 SCORE 0.1449 | TIME 12.1224\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.8707 | ACC 0.9598 | F1 SCORE 0.1293 | TIME 12.6259\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.8640 | ACC 0.9558 | F1 SCORE 0.1360 | TIME 13.1402\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.8412 | ACC 0.9641 | F1 SCORE 0.1588 | TIME 13.6564\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.8359 | ACC 0.9442 | F1 SCORE 0.1641 | TIME 14.1824\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.8510 | ACC 0.9572 | F1 SCORE 0.1490 | TIME 14.7349\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.8245 | ACC 0.9591 | F1 SCORE 0.1755 | TIME 15.2853\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.8553 | ACC 0.9669 | F1 SCORE 0.1447 | TIME 15.8260\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.7732 | ACC 0.9556 | F1 SCORE 0.2268 | TIME 16.0063\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.9739 | ACC 0.9725 | F1 SCORE 0.0261\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.9536 | ACC 0.9718 | F1 SCORE 0.0464\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.8240 | ACC 0.9595 | F1 SCORE 0.1760 | TIME 2.2778\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.8572 | ACC 0.9583 | F1 SCORE 0.1428 | TIME 2.8510\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.8080 | ACC 0.9539 | F1 SCORE 0.1920 | TIME 3.3915\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.8377 | ACC 0.9667 | F1 SCORE 0.1623 | TIME 3.9565\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.8523 | ACC 0.9692 | F1 SCORE 0.1477 | TIME 4.5016\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.8059 | ACC 0.9654 | F1 SCORE 0.1941 | TIME 5.0421\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.8349 | ACC 0.9642 | F1 SCORE 0.1651 | TIME 5.5868\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.8425 | ACC 0.9603 | F1 SCORE 0.1575 | TIME 6.1319\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.8221 | ACC 0.9553 | F1 SCORE 0.1779 | TIME 6.6829\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.8130 | ACC 0.9700 | F1 SCORE 0.1870 | TIME 7.2289\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.8132 | ACC 0.9725 | F1 SCORE 0.1868 | TIME 7.7696\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.7796 | ACC 0.9729 | F1 SCORE 0.2204 | TIME 8.3108\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.7872 | ACC 0.9678 | F1 SCORE 0.2128 | TIME 8.8986\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.8047 | ACC 0.9671 | F1 SCORE 0.1953 | TIME 9.4527\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.7966 | ACC 0.9688 | F1 SCORE 0.2034 | TIME 10.0032\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.7992 | ACC 0.9716 | F1 SCORE 0.2008 | TIME 10.5509\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.7838 | ACC 0.9685 | F1 SCORE 0.2162 | TIME 11.1013\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.8227 | ACC 0.9749 | F1 SCORE 0.1773 | TIME 11.6512\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.7895 | ACC 0.9780 | F1 SCORE 0.2105 | TIME 12.1973\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.7824 | ACC 0.9705 | F1 SCORE 0.2176 | TIME 12.7463\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.8191 | ACC 0.9712 | F1 SCORE 0.1809 | TIME 13.2950\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.8031 | ACC 0.9688 | F1 SCORE 0.1969 | TIME 13.8471\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.7719 | ACC 0.9700 | F1 SCORE 0.2281 | TIME 14.3914\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.8041 | ACC 0.9700 | F1 SCORE 0.1959 | TIME 14.9367\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.7953 | ACC 0.9767 | F1 SCORE 0.2047 | TIME 15.4853\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.7732 | ACC 0.9692 | F1 SCORE 0.2268 | TIME 16.0551\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.7803 | ACC 0.9692 | F1 SCORE 0.2197 | TIME 16.6034\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.7594 | ACC 0.9700 | F1 SCORE 0.2406 | TIME 16.7846\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.9609 | ACC 0.9666 | F1 SCORE 0.0391\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.9300 | ACC 0.9656 | F1 SCORE 0.0700\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.7881 | ACC 0.9619 | F1 SCORE 0.2119 | TIME 2.2918\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.7116 | ACC 0.9620 | F1 SCORE 0.2884 | TIME 2.8399\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.7662 | ACC 0.9684 | F1 SCORE 0.2338 | TIME 3.4069\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.7854 | ACC 0.9766 | F1 SCORE 0.2146 | TIME 3.9520\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.7851 | ACC 0.9785 | F1 SCORE 0.2149 | TIME 4.4954\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.7534 | ACC 0.9787 | F1 SCORE 0.2466 | TIME 5.0518\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.7745 | ACC 0.9740 | F1 SCORE 0.2255 | TIME 5.5979\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.8073 | ACC 0.9718 | F1 SCORE 0.1927 | TIME 6.1636\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.7286 | ACC 0.9708 | F1 SCORE 0.2714 | TIME 6.7293\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.7726 | ACC 0.9769 | F1 SCORE 0.2274 | TIME 7.2800\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.7698 | ACC 0.9760 | F1 SCORE 0.2302 | TIME 7.8484\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.7568 | ACC 0.9795 | F1 SCORE 0.2432 | TIME 8.3872\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.7592 | ACC 0.9766 | F1 SCORE 0.2408 | TIME 8.9339\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.7005 | ACC 0.9778 | F1 SCORE 0.2995 | TIME 9.4809\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.7169 | ACC 0.9740 | F1 SCORE 0.2831 | TIME 10.0265\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.7281 | ACC 0.9739 | F1 SCORE 0.2719 | TIME 10.5647\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.7539 | ACC 0.9759 | F1 SCORE 0.2461 | TIME 11.1133\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.7204 | ACC 0.9792 | F1 SCORE 0.2796 | TIME 11.6457\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.7239 | ACC 0.9783 | F1 SCORE 0.2761 | TIME 12.2795\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.7345 | ACC 0.9789 | F1 SCORE 0.2655 | TIME 12.7843\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.7410 | ACC 0.9753 | F1 SCORE 0.2590 | TIME 13.2753\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.7385 | ACC 0.9787 | F1 SCORE 0.2615 | TIME 13.7906\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.7451 | ACC 0.9820 | F1 SCORE 0.2549 | TIME 14.2836\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.7308 | ACC 0.9805 | F1 SCORE 0.2692 | TIME 14.7778\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.6648 | ACC 0.9735 | F1 SCORE 0.3352 | TIME 15.2597\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.7478 | ACC 0.9770 | F1 SCORE 0.2522 | TIME 15.7491\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.6985 | ACC 0.9780 | F1 SCORE 0.3015 | TIME 16.2567\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.7079 | ACC 0.9769 | F1 SCORE 0.2921 | TIME 16.4302\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.9311 | ACC 0.9879 | F1 SCORE 0.0689\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.8636 | ACC 0.9864 | F1 SCORE 0.1364\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-52_eye_right_mix --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : mix\n",
      "data dir: ../../../split_data/eye_right/\n",
      "ckpt dir: ./checkpoint/12-15_21-52_eye_right_mix\n",
      "log dir: ./log/12-15_21-52_eye_right_mix\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.8251 | ACC 0.9789 | F1 SCORE 0.0301 | TIME 2.2175\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.7969 | ACC 0.9230 | F1 SCORE 0.0277 | TIME 2.7978\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.7780 | ACC 0.9868 | F1 SCORE 0.0207 | TIME 3.3437\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.7565 | ACC 0.9854 | F1 SCORE 0.0242 | TIME 3.9017\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.7511 | ACC 0.9816 | F1 SCORE 0.0314 | TIME 4.4391\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.7377 | ACC 0.9829 | F1 SCORE 0.0312 | TIME 4.9831\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.7229 | ACC 0.9810 | F1 SCORE 0.0295 | TIME 5.5306\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.7147 | ACC 0.9729 | F1 SCORE 0.0334 | TIME 6.0783\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.7214 | ACC 0.9553 | F1 SCORE 0.0481 | TIME 6.6220\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.7289 | ACC 0.9415 | F1 SCORE 0.0469 | TIME 7.1577\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.7188 | ACC 0.9542 | F1 SCORE 0.0402 | TIME 7.6813\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.7059 | ACC 0.9661 | F1 SCORE 0.0370 | TIME 8.2207\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.6916 | ACC 0.9775 | F1 SCORE 0.0346 | TIME 8.7514\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.7046 | ACC 0.9710 | F1 SCORE 0.0406 | TIME 9.2834\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.6908 | ACC 0.9584 | F1 SCORE 0.0428 | TIME 9.8143\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.6774 | ACC 0.9614 | F1 SCORE 0.0481 | TIME 10.3457\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.6888 | ACC 0.9592 | F1 SCORE 0.0567 | TIME 10.8804\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.6784 | ACC 0.9484 | F1 SCORE 0.0413 | TIME 11.4107\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.6699 | ACC 0.9521 | F1 SCORE 0.0478 | TIME 11.9592\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.6784 | ACC 0.9583 | F1 SCORE 0.0663 | TIME 12.5061\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.6708 | ACC 0.9605 | F1 SCORE 0.0542 | TIME 13.0504\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.6536 | ACC 0.9580 | F1 SCORE 0.0502 | TIME 13.5939\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.6529 | ACC 0.9538 | F1 SCORE 0.0546 | TIME 14.1419\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.6705 | ACC 0.9410 | F1 SCORE 0.0547 | TIME 14.6904\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.6585 | ACC 0.9544 | F1 SCORE 0.0632 | TIME 15.2346\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.6530 | ACC 0.9578 | F1 SCORE 0.0633 | TIME 15.7830\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.6443 | ACC 0.9571 | F1 SCORE 0.0553 | TIME 16.3255\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.6520 | ACC 0.9527 | F1 SCORE 0.0615 | TIME 16.5057\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.9726 | ACC 0.7308 | F1 SCORE 0.0169\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.9598 | ACC 0.7347 | F1 SCORE 0.0192\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.6458 | ACC 0.9640 | F1 SCORE 0.0639 | TIME 2.3334\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.6365 | ACC 0.9652 | F1 SCORE 0.0639 | TIME 2.8838\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.6422 | ACC 0.9638 | F1 SCORE 0.0596 | TIME 3.4245\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.6430 | ACC 0.9592 | F1 SCORE 0.0850 | TIME 3.9911\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.6438 | ACC 0.9565 | F1 SCORE 0.0809 | TIME 4.5329\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.6337 | ACC 0.9557 | F1 SCORE 0.0730 | TIME 5.0726\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.6203 | ACC 0.9509 | F1 SCORE 0.0707 | TIME 5.6136\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.6381 | ACC 0.9376 | F1 SCORE 0.0894 | TIME 6.1579\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.6240 | ACC 0.9487 | F1 SCORE 0.0760 | TIME 6.7137\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.6512 | ACC 0.9485 | F1 SCORE 0.0722 | TIME 7.2620\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.6261 | ACC 0.9454 | F1 SCORE 0.0757 | TIME 7.8125\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.6272 | ACC 0.9490 | F1 SCORE 0.0757 | TIME 8.3563\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.6291 | ACC 0.9554 | F1 SCORE 0.0777 | TIME 8.9021\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.6158 | ACC 0.9584 | F1 SCORE 0.0748 | TIME 9.4464\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.6230 | ACC 0.9553 | F1 SCORE 0.0878 | TIME 9.9866\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.6177 | ACC 0.9592 | F1 SCORE 0.0654 | TIME 10.5304\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.6155 | ACC 0.9590 | F1 SCORE 0.0795 | TIME 11.0801\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.6054 | ACC 0.9626 | F1 SCORE 0.0743 | TIME 11.6203\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.5945 | ACC 0.9663 | F1 SCORE 0.0681 | TIME 12.1712\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.6104 | ACC 0.9640 | F1 SCORE 0.0910 | TIME 12.7181\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.6055 | ACC 0.9644 | F1 SCORE 0.0957 | TIME 13.2645\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.5889 | ACC 0.9630 | F1 SCORE 0.0811 | TIME 13.8107\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.6032 | ACC 0.9657 | F1 SCORE 0.0747 | TIME 14.3838\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.5964 | ACC 0.9641 | F1 SCORE 0.0829 | TIME 14.9309\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.5927 | ACC 0.9579 | F1 SCORE 0.0898 | TIME 15.4741\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.6097 | ACC 0.9565 | F1 SCORE 0.0871 | TIME 16.0217\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.6030 | ACC 0.9583 | F1 SCORE 0.0821 | TIME 16.5711\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.5880 | ACC 0.9586 | F1 SCORE 0.0771 | TIME 16.7599\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.6266 | ACC 0.9476 | F1 SCORE 0.0267\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.6282 | ACC 0.9455 | F1 SCORE 0.0351\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.6164 | ACC 0.9566 | F1 SCORE 0.1042 | TIME 2.1898\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.6011 | ACC 0.9540 | F1 SCORE 0.0818 | TIME 2.7639\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.5982 | ACC 0.9621 | F1 SCORE 0.0985 | TIME 3.3075\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.5927 | ACC 0.9643 | F1 SCORE 0.0693 | TIME 3.8538\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.6038 | ACC 0.9664 | F1 SCORE 0.0986 | TIME 4.3669\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.5943 | ACC 0.9712 | F1 SCORE 0.0795 | TIME 4.8519\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.6068 | ACC 0.9638 | F1 SCORE 0.1011 | TIME 5.3664\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.6031 | ACC 0.9629 | F1 SCORE 0.1186 | TIME 5.8507\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.6057 | ACC 0.9581 | F1 SCORE 0.0855 | TIME 6.3445\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.5949 | ACC 0.9515 | F1 SCORE 0.1141 | TIME 6.8502\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.5900 | ACC 0.9532 | F1 SCORE 0.1089 | TIME 7.3348\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.6184 | ACC 0.9530 | F1 SCORE 0.0964 | TIME 7.8429\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.5857 | ACC 0.9545 | F1 SCORE 0.0735 | TIME 8.3436\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.6001 | ACC 0.9483 | F1 SCORE 0.0952 | TIME 8.8617\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.6009 | ACC 0.9489 | F1 SCORE 0.1489 | TIME 9.3885\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.5846 | ACC 0.9551 | F1 SCORE 0.1139 | TIME 9.9028\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.5742 | ACC 0.9619 | F1 SCORE 0.1017 | TIME 10.5223\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.6027 | ACC 0.9583 | F1 SCORE 0.0958 | TIME 11.0560\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.5782 | ACC 0.9668 | F1 SCORE 0.1072 | TIME 11.5538\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.5622 | ACC 0.9659 | F1 SCORE 0.1041 | TIME 12.0693\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.5623 | ACC 0.9678 | F1 SCORE 0.1018 | TIME 12.5943\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.5664 | ACC 0.9667 | F1 SCORE 0.1359 | TIME 13.0986\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.5548 | ACC 0.9684 | F1 SCORE 0.0920 | TIME 13.5981\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.5737 | ACC 0.9646 | F1 SCORE 0.1116 | TIME 14.1192\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.5706 | ACC 0.9653 | F1 SCORE 0.1080 | TIME 14.6497\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.5710 | ACC 0.9667 | F1 SCORE 0.0978 | TIME 15.2050\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.5918 | ACC 0.9640 | F1 SCORE 0.1181 | TIME 15.7555\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.6018 | ACC 0.9506 | F1 SCORE 0.1858 | TIME 15.9362\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.6128 | ACC 0.9425 | F1 SCORE 0.0349\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.6087 | ACC 0.9421 | F1 SCORE 0.0476\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.5748 | ACC 0.9494 | F1 SCORE 0.1392 | TIME 2.3176\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.5797 | ACC 0.9466 | F1 SCORE 0.1217 | TIME 2.8820\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.5569 | ACC 0.9536 | F1 SCORE 0.1056 | TIME 3.4266\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.5620 | ACC 0.9533 | F1 SCORE 0.1427 | TIME 3.9715\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.5609 | ACC 0.9567 | F1 SCORE 0.1288 | TIME 4.5103\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.5649 | ACC 0.9506 | F1 SCORE 0.1515 | TIME 5.0590\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.5655 | ACC 0.9483 | F1 SCORE 0.1202 | TIME 5.5996\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.5583 | ACC 0.9531 | F1 SCORE 0.1018 | TIME 6.1514\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.5687 | ACC 0.9635 | F1 SCORE 0.1226 | TIME 6.7152\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.5852 | ACC 0.9721 | F1 SCORE 0.1161 | TIME 7.2655\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.5545 | ACC 0.9714 | F1 SCORE 0.1202 | TIME 7.8249\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.5673 | ACC 0.9678 | F1 SCORE 0.1246 | TIME 8.3620\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.5757 | ACC 0.9640 | F1 SCORE 0.1270 | TIME 8.9016\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.5630 | ACC 0.9607 | F1 SCORE 0.1527 | TIME 9.4405\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.5733 | ACC 0.9535 | F1 SCORE 0.1330 | TIME 9.9789\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.5789 | ACC 0.9535 | F1 SCORE 0.1016 | TIME 10.5216\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.5646 | ACC 0.9559 | F1 SCORE 0.1257 | TIME 11.0669\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.5698 | ACC 0.9580 | F1 SCORE 0.1446 | TIME 11.6043\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.5570 | ACC 0.9647 | F1 SCORE 0.0982 | TIME 12.1490\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.5632 | ACC 0.9644 | F1 SCORE 0.1055 | TIME 12.6935\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.5667 | ACC 0.9680 | F1 SCORE 0.1562 | TIME 13.2489\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.5593 | ACC 0.9682 | F1 SCORE 0.1146 | TIME 13.7903\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.5452 | ACC 0.9714 | F1 SCORE 0.1308 | TIME 14.3372\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.5550 | ACC 0.9694 | F1 SCORE 0.1315 | TIME 14.8900\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.5615 | ACC 0.9656 | F1 SCORE 0.1453 | TIME 15.4355\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.5745 | ACC 0.9605 | F1 SCORE 0.1356 | TIME 15.9772\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.5674 | ACC 0.9606 | F1 SCORE 0.1748 | TIME 16.5215\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.5966 | ACC 0.9574 | F1 SCORE 0.1673 | TIME 16.7008\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.5919 | ACC 0.9650 | F1 SCORE 0.0354\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.5920 | ACC 0.9616 | F1 SCORE 0.0504\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.5729 | ACC 0.9618 | F1 SCORE 0.1393 | TIME 2.1511\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.5662 | ACC 0.9640 | F1 SCORE 0.1517 | TIME 2.7008\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.5736 | ACC 0.9640 | F1 SCORE 0.1049 | TIME 3.2507\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.5803 | ACC 0.9606 | F1 SCORE 0.1391 | TIME 3.7932\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.5802 | ACC 0.9592 | F1 SCORE 0.0899 | TIME 4.3412\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.5522 | ACC 0.9567 | F1 SCORE 0.1357 | TIME 4.8866\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.5654 | ACC 0.9554 | F1 SCORE 0.1355 | TIME 5.4451\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.5721 | ACC 0.9550 | F1 SCORE 0.1430 | TIME 5.9917\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.5790 | ACC 0.9595 | F1 SCORE 0.1514 | TIME 6.5455\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.5647 | ACC 0.9693 | F1 SCORE 0.1176 | TIME 7.0991\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.5659 | ACC 0.9703 | F1 SCORE 0.1354 | TIME 7.6564\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.5599 | ACC 0.9710 | F1 SCORE 0.1524 | TIME 8.2062\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.5586 | ACC 0.9729 | F1 SCORE 0.1277 | TIME 8.7555\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.5528 | ACC 0.9664 | F1 SCORE 0.1616 | TIME 9.3049\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.5471 | ACC 0.9673 | F1 SCORE 0.1220 | TIME 9.8781\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.5605 | ACC 0.9654 | F1 SCORE 0.1394 | TIME 10.4299\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.5775 | ACC 0.9652 | F1 SCORE 0.1223 | TIME 10.9805\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.5476 | ACC 0.9682 | F1 SCORE 0.1582 | TIME 11.5367\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.5621 | ACC 0.9665 | F1 SCORE 0.1619 | TIME 12.0958\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.5496 | ACC 0.9637 | F1 SCORE 0.1517 | TIME 12.6465\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.5547 | ACC 0.9599 | F1 SCORE 0.1592 | TIME 13.1928\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.5479 | ACC 0.9564 | F1 SCORE 0.1607 | TIME 13.7055\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.5250 | ACC 0.9545 | F1 SCORE 0.1675 | TIME 14.2054\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.5416 | ACC 0.9545 | F1 SCORE 0.1581 | TIME 14.7280\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.5478 | ACC 0.9571 | F1 SCORE 0.1347 | TIME 15.2174\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.5437 | ACC 0.9582 | F1 SCORE 0.1624 | TIME 15.7084\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.5469 | ACC 0.9616 | F1 SCORE 0.1564 | TIME 16.1951\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.5119 | ACC 0.9685 | F1 SCORE 0.1395 | TIME 16.3568\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.5561 | ACC 0.9852 | F1 SCORE 0.0538\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.5528 | ACC 0.9829 | F1 SCORE 0.0744\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-54_nose_left_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : BCE\n",
      "data dir: ../../../split_data/nose_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-54_nose_left_BCE\n",
      "log dir: ./log/12-15_21-54_nose_left_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.5397 | ACC 0.9775 | F1 SCORE 0.0298 | TIME 2.1134\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.5027 | ACC 0.9352 | F1 SCORE 0.0309 | TIME 2.4534\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.4637 | ACC 0.9780 | F1 SCORE 0.0271 | TIME 2.7464\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.4095 | ACC 0.9773 | F1 SCORE 0.0312 | TIME 3.0357\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.3810 | ACC 0.9746 | F1 SCORE 0.0362 | TIME 3.3345\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.3526 | ACC 0.9758 | F1 SCORE 0.0345 | TIME 3.6310\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.3263 | ACC 0.9807 | F1 SCORE 0.0267 | TIME 3.9184\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.3139 | ACC 0.9804 | F1 SCORE 0.0268 | TIME 4.2064\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.2986 | ACC 0.9774 | F1 SCORE 0.0308 | TIME 4.5026\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.2937 | ACC 0.9764 | F1 SCORE 0.0321 | TIME 4.7985\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.2838 | ACC 0.9752 | F1 SCORE 0.0352 | TIME 5.0871\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.2754 | ACC 0.9727 | F1 SCORE 0.0379 | TIME 5.3862\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.2573 | ACC 0.9804 | F1 SCORE 0.0275 | TIME 5.6856\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.2596 | ACC 0.9752 | F1 SCORE 0.0337 | TIME 5.9858\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.2459 | ACC 0.9766 | F1 SCORE 0.0319 | TIME 6.2713\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.2344 | ACC 0.9802 | F1 SCORE 0.0261 | TIME 6.6618\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.2313 | ACC 0.9792 | F1 SCORE 0.0280 | TIME 6.9736\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.2278 | ACC 0.9766 | F1 SCORE 0.0309 | TIME 7.2623\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.2317 | ACC 0.9726 | F1 SCORE 0.0366 | TIME 7.5632\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.2148 | ACC 0.9785 | F1 SCORE 0.0279 | TIME 7.8552\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.2092 | ACC 0.9792 | F1 SCORE 0.0281 | TIME 8.1669\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.2051 | ACC 0.9773 | F1 SCORE 0.0312 | TIME 8.4601\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.2014 | ACC 0.9775 | F1 SCORE 0.0292 | TIME 8.7541\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.1935 | ACC 0.9794 | F1 SCORE 0.0271 | TIME 9.0474\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.1910 | ACC 0.9807 | F1 SCORE 0.0267 | TIME 9.3409\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.1874 | ACC 0.9789 | F1 SCORE 0.0276 | TIME 9.6353\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.1805 | ACC 0.9813 | F1 SCORE 0.0248 | TIME 9.9438\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.1875 | ACC 0.9792 | F1 SCORE 0.0245 | TIME 10.0648\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.9001 | ACC 0.6867 | F1 SCORE 0.0206\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.9202 | ACC 0.6794 | F1 SCORE 0.0148\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.1784 | ACC 0.9778 | F1 SCORE 0.0298 | TIME 2.0121\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.1733 | ACC 0.9801 | F1 SCORE 0.0279 | TIME 2.3337\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.1756 | ACC 0.9767 | F1 SCORE 0.0312 | TIME 2.6331\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.1734 | ACC 0.9769 | F1 SCORE 0.0313 | TIME 2.9233\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.1680 | ACC 0.9791 | F1 SCORE 0.0279 | TIME 3.2154\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.1664 | ACC 0.9757 | F1 SCORE 0.0327 | TIME 3.5062\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.1582 | ACC 0.9801 | F1 SCORE 0.0250 | TIME 3.7935\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.1588 | ACC 0.9776 | F1 SCORE 0.0311 | TIME 4.0837\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.1533 | ACC 0.9805 | F1 SCORE 0.0239 | TIME 4.3748\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.1515 | ACC 0.9794 | F1 SCORE 0.0255 | TIME 4.6641\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.1526 | ACC 0.9786 | F1 SCORE 0.0288 | TIME 4.9592\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.1609 | ACC 0.9726 | F1 SCORE 0.0361 | TIME 5.2632\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.1452 | ACC 0.9793 | F1 SCORE 0.0261 | TIME 5.5421\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.1430 | ACC 0.9814 | F1 SCORE 0.0227 | TIME 5.8278\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.1415 | ACC 0.9802 | F1 SCORE 0.0251 | TIME 6.1128\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.1410 | ACC 0.9791 | F1 SCORE 0.0283 | TIME 6.4202\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.1378 | ACC 0.9794 | F1 SCORE 0.0274 | TIME 6.7069\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.1508 | ACC 0.9710 | F1 SCORE 0.0357 | TIME 6.9925\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.1383 | ACC 0.9766 | F1 SCORE 0.0302 | TIME 7.2792\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.1351 | ACC 0.9778 | F1 SCORE 0.0280 | TIME 7.5729\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.1343 | ACC 0.9770 | F1 SCORE 0.0293 | TIME 7.8608\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.1274 | ACC 0.9805 | F1 SCORE 0.0251 | TIME 8.1473\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.1353 | ACC 0.9747 | F1 SCORE 0.0328 | TIME 8.4350\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.1283 | ACC 0.9787 | F1 SCORE 0.0285 | TIME 8.7331\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.1240 | ACC 0.9794 | F1 SCORE 0.0279 | TIME 9.0379\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.1311 | ACC 0.9743 | F1 SCORE 0.0315 | TIME 9.3482\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.1216 | ACC 0.9788 | F1 SCORE 0.0270 | TIME 9.6447\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.1229 | ACC 0.9790 | F1 SCORE 0.0252 | TIME 9.7671\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.1253 | ACC 0.9913 | F1 SCORE 0.0166\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.1198 | ACC 0.9939 | F1 SCORE 0.0119\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.1144 | ACC 0.9823 | F1 SCORE 0.0223 | TIME 1.9664\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.1174 | ACC 0.9794 | F1 SCORE 0.0269 | TIME 2.2725\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.1281 | ACC 0.9727 | F1 SCORE 0.0348 | TIME 2.5571\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.1199 | ACC 0.9767 | F1 SCORE 0.0296 | TIME 2.8413\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.1128 | ACC 0.9810 | F1 SCORE 0.0249 | TIME 3.1273\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.1136 | ACC 0.9794 | F1 SCORE 0.0266 | TIME 3.4114\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.1201 | ACC 0.9751 | F1 SCORE 0.0316 | TIME 3.6986\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.1244 | ACC 0.9726 | F1 SCORE 0.0338 | TIME 3.9896\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.1170 | ACC 0.9758 | F1 SCORE 0.0287 | TIME 4.2836\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.1088 | ACC 0.9799 | F1 SCORE 0.0244 | TIME 4.5795\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.1124 | ACC 0.9771 | F1 SCORE 0.0282 | TIME 4.8713\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.1062 | ACC 0.9802 | F1 SCORE 0.0251 | TIME 5.1679\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.1083 | ACC 0.9786 | F1 SCORE 0.0270 | TIME 5.4595\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.1113 | ACC 0.9761 | F1 SCORE 0.0314 | TIME 5.7412\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.1045 | ACC 0.9795 | F1 SCORE 0.0270 | TIME 6.0387\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.1083 | ACC 0.9773 | F1 SCORE 0.0291 | TIME 6.3253\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.0971 | ACC 0.9823 | F1 SCORE 0.0248 | TIME 6.6195\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.1011 | ACC 0.9806 | F1 SCORE 0.0259 | TIME 6.9116\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.1175 | ACC 0.9710 | F1 SCORE 0.0343 | TIME 7.2015\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.1108 | ACC 0.9738 | F1 SCORE 0.0325 | TIME 7.4892\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.1030 | ACC 0.9781 | F1 SCORE 0.0273 | TIME 7.7771\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.0994 | ACC 0.9797 | F1 SCORE 0.0254 | TIME 8.0717\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.0972 | ACC 0.9807 | F1 SCORE 0.0253 | TIME 8.3622\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.0964 | ACC 0.9799 | F1 SCORE 0.0265 | TIME 8.6543\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.0935 | ACC 0.9819 | F1 SCORE 0.0249 | TIME 8.9448\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.1016 | ACC 0.9777 | F1 SCORE 0.0298 | TIME 9.2456\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.1047 | ACC 0.9751 | F1 SCORE 0.0331 | TIME 9.5403\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.1070 | ACC 0.9723 | F1 SCORE 0.0419 | TIME 9.6585\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.0856 | ACC 0.9913 | F1 SCORE 0.0155\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.0779 | ACC 0.9939 | F1 SCORE 0.0118\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0003 | BATCH 0001 / 0028 | LOSS 0.0999 | ACC 0.9769 | F1 SCORE 0.0303 | TIME 1.9795\n",
      "TRAIN: EPOCH 0003 | BATCH 0002 / 0028 | LOSS 0.0919 | ACC 0.9811 | F1 SCORE 0.0270 | TIME 2.2744\n",
      "TRAIN: EPOCH 0003 | BATCH 0003 / 0028 | LOSS 0.1009 | ACC 0.9761 | F1 SCORE 0.0315 | TIME 2.5667\n",
      "TRAIN: EPOCH 0003 | BATCH 0004 / 0028 | LOSS 0.0873 | ACC 0.9827 | F1 SCORE 0.0239 | TIME 2.8639\n",
      "TRAIN: EPOCH 0003 | BATCH 0005 / 0028 | LOSS 0.1009 | ACC 0.9753 | F1 SCORE 0.0323 | TIME 3.1495\n",
      "TRAIN: EPOCH 0003 | BATCH 0006 / 0028 | LOSS 0.0913 | ACC 0.9803 | F1 SCORE 0.0262 | TIME 3.4525\n",
      "TRAIN: EPOCH 0003 | BATCH 0007 / 0028 | LOSS 0.0863 | ACC 0.9820 | F1 SCORE 0.0259 | TIME 3.7390\n",
      "TRAIN: EPOCH 0003 | BATCH 0008 / 0028 | LOSS 0.0991 | ACC 0.9761 | F1 SCORE 0.0307 | TIME 4.0244\n",
      "TRAIN: EPOCH 0003 | BATCH 0009 / 0028 | LOSS 0.0959 | ACC 0.9775 | F1 SCORE 0.0305 | TIME 4.3181\n",
      "TRAIN: EPOCH 0003 | BATCH 0010 / 0028 | LOSS 0.0874 | ACC 0.9806 | F1 SCORE 0.0265 | TIME 4.6035\n",
      "TRAIN: EPOCH 0003 | BATCH 0011 / 0028 | LOSS 0.0838 | ACC 0.9828 | F1 SCORE 0.0221 | TIME 4.8793\n",
      "TRAIN: EPOCH 0003 | BATCH 0012 / 0028 | LOSS 0.0936 | ACC 0.9779 | F1 SCORE 0.0277 | TIME 5.1680\n",
      "TRAIN: EPOCH 0003 | BATCH 0013 / 0028 | LOSS 0.0962 | ACC 0.9757 | F1 SCORE 0.0299 | TIME 5.4350\n",
      "TRAIN: EPOCH 0003 | BATCH 0014 / 0028 | LOSS 0.1036 | ACC 0.9724 | F1 SCORE 0.0345 | TIME 5.7022\n",
      "TRAIN: EPOCH 0003 | BATCH 0015 / 0028 | LOSS 0.0891 | ACC 0.9794 | F1 SCORE 0.0264 | TIME 5.9689\n",
      "TRAIN: EPOCH 0003 | BATCH 0016 / 0028 | LOSS 0.0895 | ACC 0.9786 | F1 SCORE 0.0272 | TIME 6.2321\n",
      "TRAIN: EPOCH 0003 | BATCH 0017 / 0028 | LOSS 0.0833 | ACC 0.9818 | F1 SCORE 0.0260 | TIME 6.4917\n",
      "TRAIN: EPOCH 0003 | BATCH 0018 / 0028 | LOSS 0.0928 | ACC 0.9767 | F1 SCORE 0.0302 | TIME 6.7538\n",
      "TRAIN: EPOCH 0003 | BATCH 0019 / 0028 | LOSS 0.0964 | ACC 0.9754 | F1 SCORE 0.0312 | TIME 7.0101\n",
      "TRAIN: EPOCH 0003 | BATCH 0020 / 0028 | LOSS 0.1047 | ACC 0.9707 | F1 SCORE 0.0396 | TIME 7.2876\n",
      "TRAIN: EPOCH 0003 | BATCH 0021 / 0028 | LOSS 0.0851 | ACC 0.9807 | F1 SCORE 0.0256 | TIME 7.5471\n",
      "TRAIN: EPOCH 0003 | BATCH 0022 / 0028 | LOSS 0.0812 | ACC 0.9819 | F1 SCORE 0.0249 | TIME 7.8047\n",
      "TRAIN: EPOCH 0003 | BATCH 0023 / 0028 | LOSS 0.0853 | ACC 0.9794 | F1 SCORE 0.0279 | TIME 8.0627\n",
      "TRAIN: EPOCH 0003 | BATCH 0024 / 0028 | LOSS 0.0929 | ACC 0.9759 | F1 SCORE 0.0306 | TIME 8.4231\n",
      "TRAIN: EPOCH 0003 | BATCH 0025 / 0028 | LOSS 0.0900 | ACC 0.9778 | F1 SCORE 0.0270 | TIME 8.6924\n",
      "TRAIN: EPOCH 0003 | BATCH 0026 / 0028 | LOSS 0.0953 | ACC 0.9754 | F1 SCORE 0.0305 | TIME 8.9572\n",
      "TRAIN: EPOCH 0003 | BATCH 0027 / 0028 | LOSS 0.0930 | ACC 0.9759 | F1 SCORE 0.0318 | TIME 9.2386\n",
      "TRAIN: EPOCH 0003 | BATCH 0028 / 0028 | LOSS 0.1315 | ACC 0.9555 | F1 SCORE 0.0588 | TIME 9.3547\n",
      "VALID: EPOCH 0003 | BATCH 0001 / 0002 | LOSS 0.0643 | ACC 0.9913 | F1 SCORE 0.0159\n",
      "VALID: EPOCH 0003 | BATCH 0002 / 0002 | LOSS 0.0557 | ACC 0.9939 | F1 SCORE 0.0124\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0004 | BATCH 0001 / 0028 | LOSS 0.0861 | ACC 0.9797 | F1 SCORE 0.0288 | TIME 1.9739\n",
      "TRAIN: EPOCH 0004 | BATCH 0002 / 0028 | LOSS 0.0969 | ACC 0.9742 | F1 SCORE 0.0382 | TIME 2.2797\n",
      "TRAIN: EPOCH 0004 | BATCH 0003 / 0028 | LOSS 0.0966 | ACC 0.9752 | F1 SCORE 0.0330 | TIME 2.5709\n",
      "TRAIN: EPOCH 0004 | BATCH 0004 / 0028 | LOSS 0.0993 | ACC 0.9716 | F1 SCORE 0.0372 | TIME 2.8640\n",
      "TRAIN: EPOCH 0004 | BATCH 0005 / 0028 | LOSS 0.0849 | ACC 0.9785 | F1 SCORE 0.0285 | TIME 3.1586\n",
      "TRAIN: EPOCH 0004 | BATCH 0006 / 0028 | LOSS 0.0837 | ACC 0.9794 | F1 SCORE 0.0266 | TIME 3.4504\n",
      "TRAIN: EPOCH 0004 | BATCH 0007 / 0028 | LOSS 0.0860 | ACC 0.9788 | F1 SCORE 0.0249 | TIME 3.7370\n",
      "TRAIN: EPOCH 0004 | BATCH 0008 / 0028 | LOSS 0.0839 | ACC 0.9791 | F1 SCORE 0.0263 | TIME 4.0281\n",
      "TRAIN: EPOCH 0004 | BATCH 0009 / 0028 | LOSS 0.0785 | ACC 0.9816 | F1 SCORE 0.0236 | TIME 4.3409\n",
      "TRAIN: EPOCH 0004 | BATCH 0010 / 0028 | LOSS 0.0853 | ACC 0.9784 | F1 SCORE 0.0287 | TIME 4.6389\n",
      "TRAIN: EPOCH 0004 | BATCH 0011 / 0028 | LOSS 0.0837 | ACC 0.9786 | F1 SCORE 0.0282 | TIME 4.9342\n",
      "TRAIN: EPOCH 0004 | BATCH 0012 / 0028 | LOSS 0.0788 | ACC 0.9805 | F1 SCORE 0.0282 | TIME 5.2350\n",
      "TRAIN: EPOCH 0004 | BATCH 0013 / 0028 | LOSS 0.0766 | ACC 0.9814 | F1 SCORE 0.0249 | TIME 5.5323\n",
      "TRAIN: EPOCH 0004 | BATCH 0014 / 0028 | LOSS 0.0870 | ACC 0.9775 | F1 SCORE 0.0281 | TIME 5.8340\n",
      "TRAIN: EPOCH 0004 | BATCH 0015 / 0028 | LOSS 0.0838 | ACC 0.9779 | F1 SCORE 0.0282 | TIME 6.1203\n",
      "TRAIN: EPOCH 0004 | BATCH 0016 / 0028 | LOSS 0.0878 | ACC 0.9768 | F1 SCORE 0.0286 | TIME 6.4067\n",
      "TRAIN: EPOCH 0004 | BATCH 0017 / 0028 | LOSS 0.0830 | ACC 0.9783 | F1 SCORE 0.0287 | TIME 6.7197\n",
      "TRAIN: EPOCH 0004 | BATCH 0018 / 0028 | LOSS 0.0860 | ACC 0.9767 | F1 SCORE 0.0318 | TIME 7.0051\n",
      "TRAIN: EPOCH 0004 | BATCH 0019 / 0028 | LOSS 0.0875 | ACC 0.9758 | F1 SCORE 0.0309 | TIME 7.2923\n",
      "TRAIN: EPOCH 0004 | BATCH 0020 / 0028 | LOSS 0.0801 | ACC 0.9785 | F1 SCORE 0.0313 | TIME 7.5810\n",
      "TRAIN: EPOCH 0004 | BATCH 0021 / 0028 | LOSS 0.0847 | ACC 0.9766 | F1 SCORE 0.0358 | TIME 7.8692\n",
      "TRAIN: EPOCH 0004 | BATCH 0022 / 0028 | LOSS 0.0766 | ACC 0.9805 | F1 SCORE 0.0291 | TIME 8.1766\n",
      "TRAIN: EPOCH 0004 | BATCH 0023 / 0028 | LOSS 0.0757 | ACC 0.9810 | F1 SCORE 0.0281 | TIME 8.4618\n",
      "TRAIN: EPOCH 0004 | BATCH 0024 / 0028 | LOSS 0.0924 | ACC 0.9733 | F1 SCORE 0.0391 | TIME 8.7530\n",
      "TRAIN: EPOCH 0004 | BATCH 0025 / 0028 | LOSS 0.0749 | ACC 0.9816 | F1 SCORE 0.0279 | TIME 9.0362\n",
      "TRAIN: EPOCH 0004 | BATCH 0026 / 0028 | LOSS 0.0862 | ACC 0.9766 | F1 SCORE 0.0360 | TIME 9.3199\n",
      "TRAIN: EPOCH 0004 | BATCH 0027 / 0028 | LOSS 0.0879 | ACC 0.9750 | F1 SCORE 0.0368 | TIME 9.6056\n",
      "TRAIN: EPOCH 0004 | BATCH 0028 / 0028 | LOSS 0.0837 | ACC 0.9766 | F1 SCORE 0.0344 | TIME 9.7267\n",
      "VALID: EPOCH 0004 | BATCH 0001 / 0002 | LOSS 0.0636 | ACC 0.9913 | F1 SCORE 0.0176\n",
      "VALID: EPOCH 0004 | BATCH 0002 / 0002 | LOSS 0.0553 | ACC 0.9939 | F1 SCORE 0.0137\n",
      "------------------------------------------------------------\n",
      "tensorboard --logdir ./log/12-15_21-55_nose_left_weighted_BCE --host \"warhol1.snu.ac.kr\" --port 6006\n",
      "learning rate: 1.0000e-03\n",
      "batch size: 16\n",
      "number of epoch: 5\n",
      "loss function : weighted_BCE\n",
      "data dir: ../../../split_data/nose_left/\n",
      "ckpt dir: ./checkpoint/12-15_21-55_nose_left_weighted_BCE\n",
      "log dir: ./log/12-15_21-55_nose_left_weighted_BCE\n",
      "mode: train\n",
      "device: cuda\n",
      "train_continue: off\n",
      "TRAIN: EPOCH 0000 | BATCH 0001 / 0028 | LOSS 0.7996 | ACC 0.9340 | F1 SCORE 0.0255 | TIME 1.9775\n",
      "TRAIN: EPOCH 0000 | BATCH 0002 / 0028 | LOSS 0.7576 | ACC 0.8879 | F1 SCORE 0.0327 | TIME 2.2886\n",
      "TRAIN: EPOCH 0000 | BATCH 0003 / 0028 | LOSS 0.6745 | ACC 0.9757 | F1 SCORE 0.0264 | TIME 2.5765\n",
      "TRAIN: EPOCH 0000 | BATCH 0004 / 0028 | LOSS 0.6330 | ACC 0.9468 | F1 SCORE 0.0374 | TIME 2.8707\n",
      "TRAIN: EPOCH 0000 | BATCH 0005 / 0028 | LOSS 0.5785 | ACC 0.9709 | F1 SCORE 0.0317 | TIME 3.1620\n",
      "TRAIN: EPOCH 0000 | BATCH 0006 / 0028 | LOSS 0.5531 | ACC 0.9755 | F1 SCORE 0.0341 | TIME 3.4514\n",
      "TRAIN: EPOCH 0000 | BATCH 0007 / 0028 | LOSS 0.5290 | ACC 0.9824 | F1 SCORE 0.0248 | TIME 3.7463\n",
      "TRAIN: EPOCH 0000 | BATCH 0008 / 0028 | LOSS 0.4956 | ACC 0.9776 | F1 SCORE 0.0295 | TIME 4.0311\n",
      "TRAIN: EPOCH 0000 | BATCH 0009 / 0028 | LOSS 0.4979 | ACC 0.9762 | F1 SCORE 0.0334 | TIME 4.3259\n",
      "TRAIN: EPOCH 0000 | BATCH 0010 / 0028 | LOSS 0.4445 | ACC 0.9861 | F1 SCORE 0.0207 | TIME 4.6154\n",
      "TRAIN: EPOCH 0000 | BATCH 0011 / 0028 | LOSS 0.4559 | ACC 0.9801 | F1 SCORE 0.0293 | TIME 4.9164\n",
      "TRAIN: EPOCH 0000 | BATCH 0012 / 0028 | LOSS 0.4605 | ACC 0.9767 | F1 SCORE 0.0347 | TIME 5.2046\n",
      "TRAIN: EPOCH 0000 | BATCH 0013 / 0028 | LOSS 0.4484 | ACC 0.9754 | F1 SCORE 0.0394 | TIME 5.4918\n",
      "TRAIN: EPOCH 0000 | BATCH 0014 / 0028 | LOSS 0.4237 | ACC 0.9795 | F1 SCORE 0.0327 | TIME 5.7784\n",
      "TRAIN: EPOCH 0000 | BATCH 0015 / 0028 | LOSS 0.4187 | ACC 0.9787 | F1 SCORE 0.0337 | TIME 6.0626\n",
      "TRAIN: EPOCH 0000 | BATCH 0016 / 0028 | LOSS 0.4117 | ACC 0.9777 | F1 SCORE 0.0336 | TIME 6.3474\n",
      "TRAIN: EPOCH 0000 | BATCH 0017 / 0028 | LOSS 0.4100 | ACC 0.9772 | F1 SCORE 0.0336 | TIME 6.6339\n",
      "TRAIN: EPOCH 0000 | BATCH 0018 / 0028 | LOSS 0.4199 | ACC 0.9719 | F1 SCORE 0.0418 | TIME 6.9265\n",
      "TRAIN: EPOCH 0000 | BATCH 0019 / 0028 | LOSS 0.3813 | ACC 0.9804 | F1 SCORE 0.0293 | TIME 7.2104\n",
      "TRAIN: EPOCH 0000 | BATCH 0020 / 0028 | LOSS 0.3903 | ACC 0.9773 | F1 SCORE 0.0330 | TIME 7.4927\n",
      "TRAIN: EPOCH 0000 | BATCH 0021 / 0028 | LOSS 0.3778 | ACC 0.9793 | F1 SCORE 0.0293 | TIME 7.7775\n",
      "TRAIN: EPOCH 0000 | BATCH 0022 / 0028 | LOSS 0.3837 | ACC 0.9761 | F1 SCORE 0.0358 | TIME 8.0599\n",
      "TRAIN: EPOCH 0000 | BATCH 0023 / 0028 | LOSS 0.4057 | ACC 0.9704 | F1 SCORE 0.0437 | TIME 8.3427\n",
      "TRAIN: EPOCH 0000 | BATCH 0024 / 0028 | LOSS 0.3775 | ACC 0.9752 | F1 SCORE 0.0386 | TIME 8.6304\n",
      "TRAIN: EPOCH 0000 | BATCH 0025 / 0028 | LOSS 0.3866 | ACC 0.9744 | F1 SCORE 0.0399 | TIME 8.9159\n",
      "TRAIN: EPOCH 0000 | BATCH 0026 / 0028 | LOSS 0.3544 | ACC 0.9795 | F1 SCORE 0.0333 | TIME 9.2047\n",
      "TRAIN: EPOCH 0000 | BATCH 0027 / 0028 | LOSS 0.3512 | ACC 0.9784 | F1 SCORE 0.0354 | TIME 9.4989\n",
      "TRAIN: EPOCH 0000 | BATCH 0028 / 0028 | LOSS 0.3173 | ACC 0.9847 | F1 SCORE 0.0247 | TIME 9.6193\n",
      "VALID: EPOCH 0000 | BATCH 0001 / 0002 | LOSS 0.3152 | ACC 0.9913 | F1 SCORE 0.0168\n",
      "VALID: EPOCH 0000 | BATCH 0002 / 0002 | LOSS 0.2934 | ACC 0.9939 | F1 SCORE 0.0122\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0001 | BATCH 0001 / 0028 | LOSS 0.3226 | ACC 0.9826 | F1 SCORE 0.0292 | TIME 1.9580\n",
      "TRAIN: EPOCH 0001 | BATCH 0002 / 0028 | LOSS 0.3329 | ACC 0.9807 | F1 SCORE 0.0302 | TIME 2.2574\n",
      "TRAIN: EPOCH 0001 | BATCH 0003 / 0028 | LOSS 0.3260 | ACC 0.9805 | F1 SCORE 0.0310 | TIME 2.5836\n",
      "TRAIN: EPOCH 0001 | BATCH 0004 / 0028 | LOSS 0.3208 | ACC 0.9812 | F1 SCORE 0.0288 | TIME 2.8733\n",
      "TRAIN: EPOCH 0001 | BATCH 0005 / 0028 | LOSS 0.3474 | ACC 0.9767 | F1 SCORE 0.0344 | TIME 3.1698\n",
      "TRAIN: EPOCH 0001 | BATCH 0006 / 0028 | LOSS 0.3266 | ACC 0.9795 | F1 SCORE 0.0315 | TIME 3.4516\n",
      "TRAIN: EPOCH 0001 | BATCH 0007 / 0028 | LOSS 0.3440 | ACC 0.9758 | F1 SCORE 0.0370 | TIME 3.7398\n",
      "TRAIN: EPOCH 0001 | BATCH 0008 / 0028 | LOSS 0.3256 | ACC 0.9780 | F1 SCORE 0.0335 | TIME 4.0309\n",
      "TRAIN: EPOCH 0001 | BATCH 0009 / 0028 | LOSS 0.3603 | ACC 0.9721 | F1 SCORE 0.0430 | TIME 4.3183\n",
      "TRAIN: EPOCH 0001 | BATCH 0010 / 0028 | LOSS 0.3136 | ACC 0.9813 | F1 SCORE 0.0266 | TIME 4.5977\n",
      "TRAIN: EPOCH 0001 | BATCH 0011 / 0028 | LOSS 0.3312 | ACC 0.9758 | F1 SCORE 0.0385 | TIME 4.8896\n",
      "TRAIN: EPOCH 0001 | BATCH 0012 / 0028 | LOSS 0.3124 | ACC 0.9791 | F1 SCORE 0.0339 | TIME 5.1632\n",
      "TRAIN: EPOCH 0001 | BATCH 0013 / 0028 | LOSS 0.3182 | ACC 0.9774 | F1 SCORE 0.0372 | TIME 5.4500\n",
      "TRAIN: EPOCH 0001 | BATCH 0014 / 0028 | LOSS 0.3191 | ACC 0.9771 | F1 SCORE 0.0370 | TIME 5.7440\n",
      "TRAIN: EPOCH 0001 | BATCH 0015 / 0028 | LOSS 0.3282 | ACC 0.9752 | F1 SCORE 0.0410 | TIME 6.0439\n",
      "TRAIN: EPOCH 0001 | BATCH 0016 / 0028 | LOSS 0.3136 | ACC 0.9777 | F1 SCORE 0.0381 | TIME 6.3220\n",
      "TRAIN: EPOCH 0001 | BATCH 0017 / 0028 | LOSS 0.2923 | ACC 0.9805 | F1 SCORE 0.0319 | TIME 6.6011\n",
      "TRAIN: EPOCH 0001 | BATCH 0018 / 0028 | LOSS 0.3027 | ACC 0.9780 | F1 SCORE 0.0372 | TIME 6.8956\n",
      "TRAIN: EPOCH 0001 | BATCH 0019 / 0028 | LOSS 0.3264 | ACC 0.9742 | F1 SCORE 0.0412 | TIME 7.1757\n",
      "TRAIN: EPOCH 0001 | BATCH 0020 / 0028 | LOSS 0.2952 | ACC 0.9804 | F1 SCORE 0.0306 | TIME 7.4625\n",
      "TRAIN: EPOCH 0001 | BATCH 0021 / 0028 | LOSS 0.3530 | ACC 0.9689 | F1 SCORE 0.0488 | TIME 7.7571\n",
      "TRAIN: EPOCH 0001 | BATCH 0022 / 0028 | LOSS 0.3128 | ACC 0.9759 | F1 SCORE 0.0394 | TIME 8.0357\n",
      "TRAIN: EPOCH 0001 | BATCH 0023 / 0028 | LOSS 0.2931 | ACC 0.9778 | F1 SCORE 0.0370 | TIME 8.3282\n",
      "TRAIN: EPOCH 0001 | BATCH 0024 / 0028 | LOSS 0.3028 | ACC 0.9753 | F1 SCORE 0.0421 | TIME 8.6154\n",
      "TRAIN: EPOCH 0001 | BATCH 0025 / 0028 | LOSS 0.3070 | ACC 0.9759 | F1 SCORE 0.0409 | TIME 8.9023\n",
      "TRAIN: EPOCH 0001 | BATCH 0026 / 0028 | LOSS 0.2626 | ACC 0.9836 | F1 SCORE 0.0288 | TIME 9.1777\n",
      "TRAIN: EPOCH 0001 | BATCH 0027 / 0028 | LOSS 0.2790 | ACC 0.9802 | F1 SCORE 0.0353 | TIME 9.4631\n",
      "TRAIN: EPOCH 0001 | BATCH 0028 / 0028 | LOSS 0.3185 | ACC 0.9728 | F1 SCORE 0.0486 | TIME 9.6003\n",
      "VALID: EPOCH 0001 | BATCH 0001 / 0002 | LOSS 0.2678 | ACC 0.9913 | F1 SCORE 0.0174\n",
      "VALID: EPOCH 0001 | BATCH 0002 / 0002 | LOSS 0.2454 | ACC 0.9939 | F1 SCORE 0.0127\n",
      "------------------------------------------------------------\n",
      "TRAIN: EPOCH 0002 | BATCH 0001 / 0028 | LOSS 0.3108 | ACC 0.9724 | F1 SCORE 0.0524 | TIME 2.0177\n",
      "TRAIN: EPOCH 0002 | BATCH 0002 / 0028 | LOSS 0.2786 | ACC 0.9804 | F1 SCORE 0.0352 | TIME 2.3191\n",
      "TRAIN: EPOCH 0002 | BATCH 0003 / 0028 | LOSS 0.2756 | ACC 0.9801 | F1 SCORE 0.0374 | TIME 2.7243\n",
      "TRAIN: EPOCH 0002 | BATCH 0004 / 0028 | LOSS 0.2850 | ACC 0.9774 | F1 SCORE 0.0427 | TIME 3.0147\n",
      "TRAIN: EPOCH 0002 | BATCH 0005 / 0028 | LOSS 0.2756 | ACC 0.9798 | F1 SCORE 0.0358 | TIME 3.3085\n",
      "TRAIN: EPOCH 0002 | BATCH 0006 / 0028 | LOSS 0.2971 | ACC 0.9739 | F1 SCORE 0.0478 | TIME 3.5922\n",
      "TRAIN: EPOCH 0002 | BATCH 0007 / 0028 | LOSS 0.2761 | ACC 0.9777 | F1 SCORE 0.0399 | TIME 3.8730\n",
      "TRAIN: EPOCH 0002 | BATCH 0008 / 0028 | LOSS 0.2843 | ACC 0.9776 | F1 SCORE 0.0394 | TIME 4.1824\n",
      "TRAIN: EPOCH 0002 | BATCH 0009 / 0028 | LOSS 0.2953 | ACC 0.9754 | F1 SCORE 0.0425 | TIME 4.4736\n",
      "TRAIN: EPOCH 0002 | BATCH 0010 / 0028 | LOSS 0.3177 | ACC 0.9711 | F1 SCORE 0.0486 | TIME 4.7604\n",
      "TRAIN: EPOCH 0002 | BATCH 0011 / 0028 | LOSS 0.2731 | ACC 0.9785 | F1 SCORE 0.0382 | TIME 5.0464\n",
      "TRAIN: EPOCH 0002 | BATCH 0012 / 0028 | LOSS 0.2815 | ACC 0.9776 | F1 SCORE 0.0397 | TIME 5.3376\n",
      "TRAIN: EPOCH 0002 | BATCH 0013 / 0028 | LOSS 0.2844 | ACC 0.9778 | F1 SCORE 0.0363 | TIME 5.6288\n",
      "TRAIN: EPOCH 0002 | BATCH 0014 / 0028 | LOSS 0.2935 | ACC 0.9741 | F1 SCORE 0.0498 | TIME 5.9159\n",
      "TRAIN: EPOCH 0002 | BATCH 0015 / 0028 | LOSS 0.2694 | ACC 0.9781 | F1 SCORE 0.0433 | TIME 6.2076\n",
      "TRAIN: EPOCH 0002 | BATCH 0016 / 0028 | LOSS 0.2669 | ACC 0.9801 | F1 SCORE 0.0367 | TIME 6.4923\n",
      "TRAIN: EPOCH 0002 | BATCH 0017 / 0028 | LOSS 0.3007 | ACC 0.9739 | F1 SCORE 0.0464 | TIME 6.8049\n",
      "TRAIN: EPOCH 0002 | BATCH 0018 / 0028 | LOSS 0.2413 | ACC 0.9810 | F1 SCORE 0.0373 | TIME 7.0933\n",
      "TRAIN: EPOCH 0002 | BATCH 0019 / 0028 | LOSS 0.2636 | ACC 0.9782 | F1 SCORE 0.0419 | TIME 7.3740\n",
      "TRAIN: EPOCH 0002 | BATCH 0020 / 0028 | LOSS 0.2237 | ACC 0.9846 | F1 SCORE 0.0314 | TIME 7.6572\n",
      "TRAIN: EPOCH 0002 | BATCH 0021 / 0028 | LOSS 0.2457 | ACC 0.9808 | F1 SCORE 0.0381 | TIME 7.9561\n",
      "TRAIN: EPOCH 0002 | BATCH 0022 / 0028 | LOSS 0.2629 | ACC 0.9783 | F1 SCORE 0.0431 | TIME 8.2519\n",
      "TRAIN: EPOCH 0002 | BATCH 0023 / 0028 | LOSS 0.2597 | ACC 0.9797 | F1 SCORE 0.0344 | TIME 8.5441\n",
      "TRAIN: EPOCH 0002 | BATCH 0024 / 0028 | LOSS 0.3008 | ACC 0.9721 | F1 SCORE 0.0540 | TIME 8.8433\n",
      "TRAIN: EPOCH 0002 | BATCH 0025 / 0028 | LOSS 0.2569 | ACC 0.9780 | F1 SCORE 0.0452 | TIME 9.1229\n",
      "TRAIN: EPOCH 0002 | BATCH 0026 / 0028 | LOSS 0.2793 | ACC 0.9756 | F1 SCORE 0.0494 | TIME 9.4029\n",
      "TRAIN: EPOCH 0002 | BATCH 0027 / 0028 | LOSS 0.2540 | ACC 0.9798 | F1 SCORE 0.0409 | TIME 9.6829\n",
      "TRAIN: EPOCH 0002 | BATCH 0028 / 0028 | LOSS 0.2687 | ACC 0.9773 | F1 SCORE 0.0470 | TIME 9.8002\n",
      "VALID: EPOCH 0002 | BATCH 0001 / 0002 | LOSS 0.1901 | ACC 0.9913 | F1 SCORE 0.0213\n",
      "VALID: EPOCH 0002 | BATCH 0002 / 0002 | LOSS 0.1604 | ACC 0.9939 | F1 SCORE 0.0166\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e28b4a714c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'BCE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weighted_BCE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../../../split_data/{key}/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b3153ddc3567>\u001b[0m in \u001b[0;36mtrain_unet\u001b[0;34m(data_dir, loss_name, lr, batch_size, num_epoch, ckpt_dir, log_dir, mode, train_continue, key)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mtrain_wr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semester/20f-creative-integrated-design-1/wrinkle-detection/unet/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, loss_function, num_batch, current_epoch, writer_train, device, optim)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mf1_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in new_dict:\n",
    "    new_logs = {}\n",
    "    new_ckpts = {}\n",
    "    for loss in ('BCE', 'weighted_BCE', 'f1', 'mix'):\n",
    "        new_ckpts[loss], new_logs[loss] = train_unet(f\"../../../split_data/{key}/\", loss, num_epoch=200, batch_size=16, key=key)\n",
    "    logs[key] = new_logs\n",
    "    ckpts[key] = new_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_logs['BCE'] = \"./log/11-30_17-26_BCE\"\n",
    "eye_logs['weighted_BCE'] = \"./log/11-30_18-34_weighted_BCE\"\n",
    "eye_logs['f1'] = \"./log/11-30_19-41_f1\"\n",
    "eye_logs['mix'] = \"./log/11-30_20-49_mix\"\n",
    "\n",
    "plot_f1(eye_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(eye_logs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel1",
   "language": "python",
   "name": "mykernel1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
